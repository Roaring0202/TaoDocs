<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>TaoEdu</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="Bittensor Documentation covers the usage, installation, and development of Bittensor.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Getting Started</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="before_you_build.html"><strong aria-hidden="true">1.1.</strong> Before You Build</a></li><li class="chapter-item expanded "><a href="Linux_basics.html"><strong aria-hidden="true">1.2.</strong> Linux Basics</a></li><li class="chapter-item expanded "><a href="index.html"><strong aria-hidden="true">1.3.</strong> ReadMe</a></li><li class="chapter-item expanded "><a href="bounty_system.html"><strong aria-hidden="true">1.4.</strong> The Bounty System</a></li><li class="chapter-item expanded "><a href="client_commands.html"><strong aria-hidden="true">1.5.</strong> Btcli Basics</a></li></ol></li><li class="chapter-item expanded "><a href="baseline_skills.html"><strong aria-hidden="true">2.</strong> The Skills You'll Need</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="rlhf.html"><strong aria-hidden="true">2.1.</strong> How to train an LLM?</a></li><li class="chapter-item expanded "><a href="md_book.html"><strong aria-hidden="true">2.2.</strong> Learn to write Documentation!</a></li></ol></li><li class="chapter-item expanded "><a href="finney.html"><strong aria-hidden="true">3.</strong> Finney and Prompting</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="prompting_examples.html"><strong aria-hidden="true">3.1.</strong> Explanation of Prompt Scripts</a></li><li class="chapter-item expanded "><a href="prompting_example2.html"><strong aria-hidden="true">3.2.</strong> More Prompting Examples</a></li></ol></li><li class="chapter-item expanded "><a href="generate_signature.html"><strong aria-hidden="true">4.</strong> Information for Validation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="verify_signature.html"><strong aria-hidden="true">4.1.</strong> Verify Validator</a></li><li class="chapter-item expanded "><a href="gating_model.html"><strong aria-hidden="true">4.2.</strong> Gating Model</a></li><li class="chapter-item expanded "><a href="neuron.html"><strong aria-hidden="true">4.3.</strong> Neurons</a></li><li class="chapter-item expanded "><a href="core_validator_init.html"><strong aria-hidden="true">4.4.</strong> Core Validator Explanation</a></li></ol></li><li class="chapter-item expanded "><a href="rewards.html"><strong aria-hidden="true">5.</strong> Mining</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="bittensor_init.html"><strong aria-hidden="true">5.1.</strong> Synopsis of Bittensor Code</a></li><li class="chapter-item expanded "><a href="epochs.html"><strong aria-hidden="true">5.2.</strong> What's an Epoch?</a></li><li class="chapter-item expanded "><a href="miner_commands.html"><strong aria-hidden="true">5.3.</strong> Miner Commands</a></li><li class="chapter-item expanded "><a href="miner_analysis.html"><strong aria-hidden="true">5.4.</strong> Analysis of a Miner Template</a></li><li class="chapter-item expanded "><a href="register_cuda.html"><strong aria-hidden="true">5.5.</strong> Cuda PoW</a></li><li class="chapter-item expanded "><a href="keyfile_impl.html"><strong aria-hidden="true">5.6.</strong> Managing Keys</a></li></ol></li><li class="chapter-item expanded "><a href="dataset_impl.html"><strong aria-hidden="true">6.</strong> GenesisTextDataSet and more on Data</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="dataset_mock.html"><strong aria-hidden="true">6.1.</strong> Mock DataSet</a></li><li class="chapter-item expanded "><a href="_logging_init.html"><strong aria-hidden="true">6.2.</strong> Looking at Logs</a></li><li class="chapter-item expanded "><a href="metagraph_impl.html"><strong aria-hidden="true">6.3.</strong> What's a MetaGraph?</a></li></ol></li><li class="chapter-item expanded "><a href="networking.html"><strong aria-hidden="true">7.</strong> Networking</a></li><li class="chapter-item expanded "><a href="registration.html"><strong aria-hidden="true">8.</strong> Registration</a></li><li class="chapter-item expanded "><a href="axon_init.html"><strong aria-hidden="true">9.</strong> Axons</a></li><li class="chapter-item expanded "><a href="dendrite_impl.html"><strong aria-hidden="true">10.</strong> Dendrites</a></li><li class="chapter-item expanded "><a href="prometheus_init.html"><strong aria-hidden="true">11.</strong> The Prometheus Module</a></li><li class="chapter-item expanded "><a href="receptor_impl.html"><strong aria-hidden="true">12.</strong> Receptors</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">TaoEdu</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="what-is-bittensor"><a class="header" href="#what-is-bittensor">What is Bittensor?</a></h1>
<p>Bittensor is an internet-scale mining network that encourages miners to host and train machine learning models. The network uses token-based incentives to promote its growth and to distribute value directly to the individuals providing that value. Bittensor is an open network, accessible to all participants, and no individual or group has full control over its learning, profit generation, or access.</p>
<p>Some key features of Bittensor include:</p>
<ul>
<li>Querying the Bittensor network as a client</li>
<li>Running and building Bittensor miners and validators for mining TAO</li>
<li>Pulling network state information</li>
<li>Managing TAO wallets, balances, transfers, etc.</li>
</ul>
<h2 id="documentation-overview"><a class="header" href="#documentation-overview">Documentation Overview</a></h2>
<p>This documentation is divided into several sections to help you get started with Bittensor:</p>
<ol>
<li><strong>Introduction</strong>: An overview of Bittensor and its key features (this section)</li>
<li><strong>Installation</strong>: Step-by-step instructions for installing Bittensor</li>
<li><strong>Usage</strong>: Guides on how to use Bittensor as a client, miner, and validator.</li>
<li><strong>API Reference</strong>: Detailed information on Bittensor's API and its various functions.</li>
<li><strong>The rest of it</strong>: Answers to the enigma that is this network and how it functions from the perspective of code, computer science, and the construction of a Neural Network. </li>
</ol>
<h1 id="the-first-of-its-kind-nonetheless"><a class="header" href="#the-first-of-its-kind-nonetheless">The first of it's kind, nonetheless.</a></h1>
<p>We hope you find this documentation helpful as you explore and use Bittensor. If you have any questions or need further assistance, please don't hesitate to reach out to the community through Discord, and the moderators of both official and unofficial channels can probably help with whatever problem you may be having. </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advice-for-windows-users-before-learning"><a class="header" href="#advice-for-windows-users-before-learning">Advice for Windows Users Before Learning</a></h1>
<p><code>Learn how to use WSL</code></p>
<p>The Bittensor Network is a decentralized machine learning platform that enables developers to train and deploy machine learning models in a secure, distributed environment. As a developer, you may need to interact with this network on a regular basis. One way to make this interaction seamless and efficient is by using the Windows Subsystem for Linux (WSL). This essay will discuss the benefits of using WSL for interacting with the Bittensor Network.</p>
<h2 id="enhanced-developer-experience"><a class="header" href="#enhanced-developer-experience">Enhanced Developer Experience</a></h2>
<p>WSL allows you to run a Linux distribution alongside your existing Windows operating system. This means that you can leverage the power of both Windows and Linux environments, creating a more versatile development experience. With WSL, you can use the same Linux tools and utilities that you are familiar with, without having to dual boot or set up a virtual machine. This can significantly improve your workflow and productivity when working with the Bittensor Network.</p>
<h2 id="consistent-cross-platform-development"><a class="header" href="#consistent-cross-platform-development">Consistent Cross-Platform Development</a></h2>
<p>When working with decentralized networks like Bittensor, it's important to ensure that your code runs consistently across different platforms. With WSL, you can develop and test your code in a Linux environment, which is often the target environment for many server-side applications. This helps ensure that your code will work as expected when deployed on the Bittensor Network, reducing the chances of encountering platform-specific issues.</p>
<h2 id="simplified-setup-and-configuration"><a class="header" href="#simplified-setup-and-configuration">Simplified Setup and Configuration</a></h2>
<p>Setting up a development environment for the Bittensor Network may involve installing various dependencies, libraries, and tools. With WSL, you can easily install these components using familiar package managers like apt or yum. This simplifies the setup process and allows you to quickly get started with the Bittensor Network. Furthermore, WSL provides better integration with Windows, making it easier to share files and resources between the two operating systems.</p>
<h2 id="improved-security"><a class="header" href="#improved-security">Improved Security</a></h2>
<p>WSL offers a sandboxed environment, isolating your Linux distribution from your Windows system. This can help enhance the security of your development environment, particularly when working with sensitive data or untrusted code on the Bittensor Network. By keeping your Linux environment separate from your primary Windows system, you can minimize potential security risks.</p>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>In summary, using the Windows Subsystem for Linux (WSL) to interact with the Bittensor Network offers a range of benefits, including an enhanced developer experience, consistent cross-platform development, simplified setup and configuration, and improved security. By leveraging the power of both Windows and Linux, WSL allows you to work efficiently with the Bittensor Network, ultimately helping you to create more reliable and secure machine learning models in a decentralized environment.</p>
<p>To conclude here, I want to state <strong>the most important skill</strong> for somebody to have when beginning with Bittensor, even just as a client: Computer Science. You're going to have to learn about Linux, you're going to have to learn about Python scripting - and that's okay. It'll take some time, but if you have ChatGPT or something similar, then you should be able to figure things out just fine. How do you think I wrote these documents? Ain't no way..</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linux_basics"><a class="header" href="#linux_basics">Linux_Basics</a></h1>
<h5 id="i-must-note-the-importance-of-being-comfortable-navigating-linux-and-reading-code-when-it-comes-to-developing-on-the-bittensor-network-rust-is-also-a-good-language-for-documentation-as-it-is-easy-to-lose-track-of-all-the-knowledge-acquired-at-some-point-it-will-become-second-nature---you-will-remember-what-cat-does-what-a-pipe-isexample--grep-and-you-will-understand-how-to-use-wsl-speaking-of-wsl-you-should-refer-to-the-before-you-build-section-of-the-docs"><a class="header" href="#i-must-note-the-importance-of-being-comfortable-navigating-linux-and-reading-code-when-it-comes-to-developing-on-the-bittensor-network-rust-is-also-a-good-language-for-documentation-as-it-is-easy-to-lose-track-of-all-the-knowledge-acquired-at-some-point-it-will-become-second-nature---you-will-remember-what-cat-does-what-a-pipe-isexample--grep-and-you-will-understand-how-to-use-wsl-speaking-of-wsl-you-should-refer-to-the-before-you-build-section-of-the-docs"><strong>I must note the importance of being comfortable navigating Linux and reading code when it comes to developing on the Bittensor Network. Rust is also a good language for documentation, as it is easy to lose track of all the knowledge acquired. At some point, it will become second nature - you will remember what cat does, what a pipe is(example | grep), and you will understand how to use WSL. Speaking of WSL, you should refer to the &quot;before you build&quot; section of the Docs.</strong></a></h5>
<ul>
<li><code>ls</code>: list files in the current directory</li>
<li><code>cd</code>: change directory</li>
<li><code>mkdir</code>: make a new directory</li>
<li><code>rmdir</code>: remove a directory</li>
<li><code>touch</code>: create a new file or update the modification time of an existing file</li>
<li><code>rm</code>: remove a file or directory</li>
<li><code>cp</code>: copy files or directories</li>
<li><code>mv</code>: move files or directories</li>
<li><code>cat</code>: display the contents of a file</li>
<li><code>grep</code>: search for a pattern in a file or set of files</li>
<li><code>chmod</code>: change the permissions of a file or directory</li>
<li><code>chown</code>: change the ownership of a file or directory</li>
<li><code>ps</code>: display information about running processes</li>
<li><code>kill</code>: send a signal to a process to terminate it</li>
<li><code>sudo</code>: execute a command as the superuser (root)</li>
<li><code>tar</code>: create or extract compressed archive files</li>
<li><code>ssh</code>: connect to a remote server via SSH protocol</li>
<li><code>scp</code>: copy files between local and remote systems using SSH protocol</li>
<li><code>ping</code>: test network connectivity to a server or website</li>
<li><code>ifconfig</code>: display network interface configuration</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><p>Hi, this is a community project supported by members of the Bittensor community.</p>
<p>The goal here is create the best source of documentation to set people on the right path with Bittensor. This means we must arm the people with the knowledge of Linux, Python as well as the commands found within this intricate network. It is also important to recognize the roles of validators and miners, and we will go into more explanation on their respective sections. This is an opensource project, just as Bittensor itself is. If you think you can contribute to better documentation, then please hop aboard and contribute to the documentation - somebody will review your changes, surely. </p>
<p>TaoEdu strives to be an incentivized learning community within the Bittensor Ecosystem where intelligence can grow and this can become a more common knowledge. </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="how-does-the-bounty-system-work"><a class="header" href="#how-does-the-bounty-system-work">How does the bounty system work?</a></h1>
<p>It is important to note here that Bounties have been a concept in programming for a long time, and the core of it's philosophy is this: </p>
<h2 id="do-good-work-recieve-money"><a class="header" href="#do-good-work-recieve-money"><strong>Do good work, recieve money.</strong></a></h2>
<p>Here on the Bittensor Network, it is no different, but the current bounties revolve around training Langauge models generally - there are also community funded endeavors, and those happen on more of an individual basis. With that being said, if you think you can help people with their project, then show you are capable and work may come your way. Or, feel free to submit a formal application towards Bittensors e-mail and put yourself out there. Work cannot find you if you have no projects to showcase your abilities, so start building. </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="btcli-guide"><a class="header" href="#btcli-guide">Btcli Guide</a></h1>
<h4 id="i-assume-most-people-who-use-bittensor-frequently-probably-know-what-these-commands-are-but-if-youre-completely-new-to-this-project-these-are-pretty-important"><a class="header" href="#i-assume-most-people-who-use-bittensor-frequently-probably-know-what-these-commands-are-but-if-youre-completely-new-to-this-project-these-are-pretty-important"><em>I assume most people who use Bittensor frequently probably know what these commands are, but if you're completely new to this project, these are pretty important.</em></a></h4>
<pre><code class="language-- btcli (insert command) will help you navigate through the network  have this open so you don't have to call -h over and over again.">
- list               - List wallets
- stake              - Stake to your hotkey accounts.
- update             - Update bittensor
- inspect            - Inspect a wallet (cold, hot) pair
- weights            - Show weights from chain.
- unstake            - Unstake from hotkey accounts.
- overview           - Show registered account overview.
- register           - Register a wallet to a network.
- transfer           - Transfer Tao between accounts.
- nominate           - Become a delegate on the network
- new_hotkey         - Creates a new hotkey (for running a miner) under the specified path.
- metagraph          - Metagraph commands
- set_weights        - Setting weights on the chain.
- new_coldkey        - Creates a new coldkey (for containing balance) under the specified path.
- new_hotkey         - Creates a new hotkey (for running a miner) under the specified path.
- my_delegates       - Show all delegates where I am delegating a positive amount of stake
- list_subnets       - List all subnets on the network
- regen_hotkey       - Regenerates a hotkey from a passed mnemonic
- regen_coldkey      - Regenerates a coldkey from a passed value
- delegate           - Delegate Stake to an account.
- undelegate         - Undelegate Stake from an account.
- list_delegates     - List all delegates on the network
- regen_coldkeypub   - Regenerates a coldkeypub from the public part of the coldkey.
- recycle_register   - Register a wallet to a network.```
 

### This is generated by using btcli -h in a Linux terminal. 

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="the-following-is-a-summary-of-the-skills-one-may-need-to-learn-as-they-progress-through-their-journey-here"><a class="header" href="#the-following-is-a-summary-of-the-skills-one-may-need-to-learn-as-they-progress-through-their-journey-here">The following is a summary of the skills one may need to learn as they progress through their journey here.</a></h2>
<p><strong>It should be noted that the field is constantly evolving and shifting, but there is still a baseline.</strong></p>
<p><strong>To operate effectively on the Bittensor network, an individual would need a diverse set of skills that cover the technical, conceptual, and practical aspects of the platform.</strong></p>
<h1 id="bittensor-skillset-overview"><a class="header" href="#bittensor-skillset-overview">Bittensor Skillset Overview</a></h1>
<p>The following summary outlines the essential skills for anyone looking to effectively contribute to the Bittensor network. The field is constantly evolving and shifting; however, these foundational skills provide a solid starting point.</p>
<h2 id="essential-skills-for-bittensor-network-operations"><a class="header" href="#essential-skills-for-bittensor-network-operations">Essential Skills for Bittensor Network Operations</a></h2>
<p>To succeed in the Bittensor ecosystem, individuals should possess a diverse set of skills, covering technical, conceptual, and practical aspects of the platform. Some key skills include:</p>
<ol>
<li><strong>Python Programming</strong></li>
</ol>
<p>Proficiency in Python is crucial since the Bittensor library is primarily written in Python.</p>
<ol start="2">
<li><strong>Machine Learning</strong></li>
</ol>
<p>A strong understanding of machine learning concepts, particularly deep learning and natural language processing, is essential for building and deploying models on the network.</p>
<ol start="3">
<li><strong>PyTorch</strong></li>
</ol>
<p>Familiarity with the PyTorch library is necessary, as Bittensor utilizes it for constructing and training models.</p>
<ol start="4">
<li><strong>Distributed Systems</strong></li>
</ol>
<p>An understanding of distributed computing concepts is crucial for working effectively with the decentralized nature of Bittensor.</p>
<ol start="5">
<li><strong>Cryptography and Blockchain</strong></li>
</ol>
<p>Knowledge of cryptography and blockchain technology is vital, as the Bittensor network relies on these concepts for security and consensus.</p>
<ol start="6">
<li><strong>APIs and Networking</strong></li>
</ol>
<p>Experience working with APIs and networking protocols is essential, given Bittensor's reliance on communication between nodes in the network.</p>
<ol start="7">
<li><strong>Problem Solving and Debugging</strong></li>
</ol>
<p>Strong problem-solving and debugging skills are necessary to identify and address issues in a complex environment.</p>
<ol start="8">
<li><strong>Documentation and Communication</strong></li>
</ol>
<p>The ability to read and comprehend technical documentation, as well as effectively communicate with other developers and users on the Bittensor platform, is crucial for success in this ecosystem.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="introduction-to-rlhfreinforcement-learning-from-human-feedback"><a class="header" href="#introduction-to-rlhfreinforcement-learning-from-human-feedback">Introduction to RLHF(Reinforcement Learning from Human Feedback)</a></h1>
<p>There's a good article on <a href="https://huggingface.co/blog/rlhf">HuggingFace</a> about this subject, but tl;dr: </p>
<p>By interacting with the AI and fine-tuning it towards a particular use-case, you can build good models. If you can build good models, you can be rewarded by the Bittensor Network. Part of the reason it's so competitive here is because the information has long been understood by the people with long-standing, but they're busy. Anybody who works within this ecosystem can tell you two things:</p>
<ol>
<li>Things move quickly. </li>
<li>Things break and require human input.</li>
</ol>
<h1 id="reinforcement-learning-from-human-feedback-rlhf"><a class="header" href="#reinforcement-learning-from-human-feedback-rlhf">Reinforcement Learning from Human Feedback (RLHF)</a></h1>
<p>Reinforcement Learning from Human Feedback (RLHF) is a challenging concept that involves multiple-model training processes and different stages of deployment. In this summary, we break down the training process into three core steps:</p>
<ol>
<li><strong>Pretraining a language model (LM)</strong></li>
<li><strong>Gathering data and training a reward model</strong></li>
<li><strong>Fine-tuning the LM with reinforcement learning</strong></li>
</ol>
<h2 id="pretraining-language-models"><a class="header" href="#pretraining-language-models">Pretraining Language Models</a></h2>
<p>As a starting point, RLHF uses a language model that has already been pretrained with classical pretraining objectives. Examples of such models include OpenAI's GPT-3, Anthropic's transformer models, and DeepMind's 280 billion parameter model Gopher. This initial model can be fine-tuned on additional text or conditions, but it's not strictly necessary.</p>
<p>There is no clear answer on the &quot;best&quot; model for the starting point of RLHF, as the design space of options in RLHF training is not thoroughly explored.</p>
<h2 id="gathering-and-generating-data-for-training-a-reward-model"><a class="header" href="#gathering-and-generating-data-for-training-a-reward-model">Gathering and Generating Data for Training a Reward Model</a></h2>
<p>To train a reward model, you need to gather or generate data that represents human preferences. The process typically involves the following steps:</p>
<ol>
<li>
<p><strong>Collecting demonstrations:</strong> Obtain samples of human-generated responses to various input prompts. These demonstrations provide a baseline for what the AI system should be able to achieve.</p>
</li>
<li>
<p><strong>Creating comparison data:</strong> Generate multiple possible responses for a given input using the pretrained language model. Have human raters evaluate and rank these responses based on their quality, relevance, and adherence to other desired criteria.</p>
</li>
<li>
<p><strong>Aggregating rankings:</strong> Aggregate the rankings provided by human raters to create a more robust and reliable dataset for training the reward model.</p>
</li>
<li>
<p><strong>Training the reward model:</strong> Train a reward model using the collected demonstrations and comparison data. This model will be used to evaluate the quality of the AI system's responses during the fine-tuning stage.</p>
</li>
</ol>
<p>Here's a more detailed breakdown of each step:</p>
<h3 id="collecting-demonstrations"><a class="header" href="#collecting-demonstrations">Collecting Demonstrations</a></h3>
<ul>
<li>Create a set of input prompts that represent a wide range of tasks and situations.</li>
<li>Have human experts provide responses to these prompts, following guidelines that emphasize the desired qualities in the AI system's responses.</li>
</ul>
<h3 id="creating-comparison-data"><a class="header" href="#creating-comparison-data">Creating Comparison Data</a></h3>
<ul>
<li>For each input prompt, generate multiple potential responses using the pretrained language model.</li>
<li>Present these responses to human raters, who will rank them based on quality, relevance, and other criteria specified in the guidelines.</li>
</ul>
<h3 id="aggregating-rankings"><a class="header" href="#aggregating-rankings">Aggregating Rankings</a></h3>
<ul>
<li>Collect rankings from multiple human raters to create a more reliable dataset.</li>
<li>Apply statistical techniques, such as the Bradley-Terry model, to aggregate individual rankings into a single, consensus-based ranking.</li>
</ul>
<h3 id="training-the-reward-model"><a class="header" href="#training-the-reward-model">Training the Reward Model</a></h3>
<ul>
<li>Use the collected demonstrations and aggregated rankings to train a reward model that can evaluate the quality of the AI system's responses.</li>
<li>The reward model will be used during the reinforcement learning stage to fine-tune the AI system's responses based on human preferences.</li>
</ul>
<p>By following these steps, you can gather and generate data that accurately represents human preferences and use it to train a reward model for RLHF.</p>
<h2 id="fine-tuning-the-language-model-with-reinforcement-learning"><a class="header" href="#fine-tuning-the-language-model-with-reinforcement-learning">Fine-Tuning the Language Model with Reinforcement Learning</a></h2>
<p>After gathering data and training the reward model, the next step is to fine-tune the pretrained language model using reinforcement learning. This process involves:</p>
<ol>
<li><strong>Sampling responses:</strong> Generate multiple candidate responses for a given input prompt using the pretrained language model.</li>
<li><strong>Evaluating responses:</strong> Use the trained reward model to rank and score the candidate responses based on their quality and adherence to human preferences.</li>
<li><strong>Updating the language model:</strong> Apply reinforcement learning algorithms, such as Proximal Policy Optimization (PPO), to update the language model's parameters based on the reward model's evaluations.</li>
</ol>
<p>Here's a more detailed breakdown of each step:</p>
<h3 id="sampling-responses"><a class="header" href="#sampling-responses">Sampling Responses</a></h3>
<ul>
<li>For a given input prompt, use the pretrained language model to generate a set of candidate responses.</li>
<li>Apply techniques such as temperature scaling, top-k sampling, or nucleus sampling to control the diversity and quality of the generated responses.</li>
</ul>
<h3 id="evaluating-responses"><a class="header" href="#evaluating-responses">Evaluating Responses</a></h3>
<ul>
<li>Use the trained reward model to evaluate and score each candidate response based on its quality, relevance, and alignment with human preferences.</li>
<li>These scores will serve as the basis for updating the language model's parameters through reinforcement learning.</li>
</ul>
<h3 id="updating-the-language-model"><a class="header" href="#updating-the-language-model">Updating the Language Model</a></h3>
<ul>
<li>Apply reinforcement learning algorithms, such as Proximal Policy Optimization (PPO), to update the language model's parameters based on the reward model's evaluations.</li>
<li>This process involves optimizing the language model's policy to maximize the expected reward, which in this case is the score assigned by the reward model.</li>
</ul>
<p>By following these steps, you can fine-tune the pretrained language model to better align with human preferences and improve its overall performance. This process can be iterated multiple times to further refine the AI system's behavior.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="learn-to-write-documentation"><a class="header" href="#learn-to-write-documentation">Learn to write Documentation!</a></h1>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="example-python-script-with-a-prompt"><a class="header" href="#example-python-script-with-a-prompt">Example Python Script with a prompt.</a></h1>
<pre><code>import bittensor as bt

response = bt.prompt('What is your name?')

print(response)
</code></pre>
<p><strong>This is just one example of a very simple prompt that gets a response from the Network.</strong></p>
<ol>
<li>Response is slow!! y?! </li>
</ol>
<ul>
<li>More TAO = Faster Prompting. Staked TAO on the Validator hosting your particular prompting Network, prompted with your wallet, allows you to earn TAO whilst using it as an API. </li>
</ul>
<ol start="2">
<li>How can I get TAO?</li>
</ol>
<ul>
<li>Tensor.Exchange</li>
<li>Find somebody to work for(bounty systems) and get paid in BTC, use it to buy TAO. </li>
<li>Use BTC to buy RunPod Servers or other GPU hosting services, Fine tune a model and mine TAO with it. </li>
</ul>
<ol start="3">
<li>Why is it so complicated?</li>
</ol>
<ul>
<li>If it was easy, everybody would be doing it. It'll get easier over time. </li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><pre><code class="language-import bittensor as bt">from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

llm = bt.BittensorLLM(wallet_name=&quot;default&quot;)

conversation = ConversationChain(
    llm=llm,
    verbose=True,
    memory=ConversationBufferMemory()
)

conversation.predict('what is the capitol of Texas?')```

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="validator-information-signing-from-bittensorbittensorscriptsvalidator_info_signaturegeneratepy"><a class="header" href="#validator-information-signing-from-bittensorbittensorscriptsvalidator_info_signaturegeneratepy">Validator Information Signing from bittensor/bittensor/scripts/validator_info_signature/generate.py</a></h1>
<p>This script gathers information about a validator and creates a signed message for that information. The information includes the mnemonic of the validator's hotkey, a descriptive name, a URL, and a short description.</p>
<h2 id="process"><a class="header" href="#process">Process</a></h2>
<ol>
<li>Import the required libraries: <code>json</code> and <code>bittensor</code>.</li>
<li>Request user input for the following information:
<ul>
<li>Validator's hotkey mnemonic</li>
<li>Descriptive name for the validator</li>
<li>Validator URL</li>
<li>Short description for the validator</li>
</ul>
</li>
<li>Create a keypair from the mnemonic.</li>
<li>Create a dictionary with the validator's information.</li>
<li>Convert the dictionary to a JSON-formatted string.</li>
<li>Sign the JSON string using the keypair.</li>
<li>Verify the signature and print the results.</li>
</ol>
<h2 id="functions"><a class="header" href="#functions">Functions</a></h2>
<h3 id="bittensorkeypaircreate_from_mnemonicmnemonic"><a class="header" href="#bittensorkeypaircreate_from_mnemonicmnemonic">bittensor.Keypair.create_from_mnemonic(mnemonic)</a></h3>
<ul>
<li><strong>Description</strong>: Creates a keypair object from a given mnemonic.</li>
<li><strong>Parameters</strong>:
<ul>
<li><code>mnemonic</code> (str): The mnemonic string for the validator's hotkey.</li>
</ul>
</li>
<li><strong>Returns</strong>: A <code>bittensor.Keypair</code> object.</li>
</ul>
<h3 id="bittensorkeypairss58_address"><a class="header" href="#bittensorkeypairss58_address">bittensor.Keypair(ss58_address)</a></h3>
<ul>
<li><strong>Description</strong>: Initializes a keypair object with the given SS58 address.</li>
<li><strong>Parameters</strong>:
<ul>
<li><code>ss58_address</code> (str): The SS58 address of the keypair.</li>
</ul>
</li>
<li><strong>Returns</strong>: A <code>bittensor.Keypair</code> object.</li>
</ul>
<h3 id="keypairsigndata"><a class="header" href="#keypairsigndata">keypair.sign(data)</a></h3>
<ul>
<li><strong>Description</strong>: Signs a message (data) using the keypair.</li>
<li><strong>Parameters</strong>:
<ul>
<li><code>data</code> (str): The message to be signed.</li>
</ul>
</li>
<li><strong>Returns</strong>: A signature string.</li>
</ul>
<h3 id="bittensorkeypairverifydata-signature"><a class="header" href="#bittensorkeypairverifydata-signature">bittensor.Keypair.verify(data, signature)</a></h3>
<ul>
<li><strong>Description</strong>: Verifies the signature of a signed message using the keypair.</li>
<li><strong>Parameters</strong>:
<ul>
<li><code>data</code> (str): The original message that was signed.</li>
<li><code>signature</code> (str): The signature of the message.</li>
</ul>
</li>
<li><strong>Returns</strong>: A boolean value indicating whether the signature is valid (<code>True</code>) or not (<code>False</code>).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="verify-validator-from"><a class="header" href="#verify-validator-from">Verify Validator from</a></h1>
<p><strong>bittensor/bittensor/scripts/validator_info_signature/verify.py</strong>
This script verifies the validator's signed information provided by the user. The user needs to input the validator information and the validator signature.</p>
<h2 id="process-1"><a class="header" href="#process-1">Process</a></h2>
<ol>
<li>Import the required libraries: <code>json</code>, <code>bittensor</code>, and <code>binascii</code>.</li>
<li>Request user input for the following information:
<ul>
<li>Validator information</li>
<li>Validator signature</li>
</ul>
</li>
<li>Convert the signature from hexadecimal to binary.</li>
<li>Create a keypair using the validator's SS58 address.</li>
<li>Verify the signature using the keypair and print the results.</li>
</ol>
<h2 id="functions-1"><a class="header" href="#functions-1">Functions</a></h2>
<h3 id="bittensorkeypairss58_address-1"><a class="header" href="#bittensorkeypairss58_address-1">bittensor.Keypair(ss58_address)</a></h3>
<ul>
<li><strong>Description</strong>: Initializes a keypair object with the given SS58 address.</li>
<li><strong>Parameters</strong>:
<ul>
<li><code>ss58_address</code> (str): The SS58 address of the keypair.</li>
</ul>
</li>
<li><strong>Returns</strong>: A <code>bittensor.Keypair</code> object.</li>
</ul>
<h3 id="binasciiunhexlifydata"><a class="header" href="#binasciiunhexlifydata">binascii.unhexlify(data)</a></h3>
<ul>
<li><strong>Description</strong>: Converts a hexadecimal string to binary data.</li>
<li><strong>Parameters</strong>:
<ul>
<li><code>data</code> (str): The hexadecimal string to be converted.</li>
</ul>
</li>
<li><strong>Returns</strong>: Binary data.</li>
</ul>
<h3 id="keypairverifydata-signature"><a class="header" href="#keypairverifydata-signature">keypair.verify(data, signature)</a></h3>
<ul>
<li><strong>Description</strong>: Verifies the signature of a signed message using the keypair.</li>
<li><strong>Parameters</strong>:
<ul>
<li><code>data</code> (str): The original message that was signed.</li>
<li><code>signature</code> (str): The signature of the message.</li>
</ul>
</li>
<li><strong>Returns</strong>: A boolean value indicating whether the signature is valid (<code>True</code>) or not (<code>False</code>).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gating-model-high-level-over-view"><a class="header" href="#gating-model-high-level-over-view">Gating model High Level Over-view</a></h1>
<p>This file defines a GatingModel class, which is a PyTorch module designed for the Bittensor network. At a high level, the class is responsible for encoding input messages, generating scores for each unique identifier (uid) in the network, and updating the model based on mean squared error loss between the normalized scores and normalized rewards.</p>
<p>The GatingModel class leverages a pre-trained transformer-based language model as its encoding layer. It then applies a linear layer to generate scores for each uid. To optimize the model, it uses the stochastic gradient descent (SGD) algorithm with configurable learning rate and momentum.</p>
<p>To use the class, a user needs to create an instance of GatingModel, providing necessary configuration details, such as the pre-trained model name and number of uids. Once the instance is created, the user can call the forward method to obtain scores for a given input message and use the backward method to update the model based on rewards obtained from the network.</p>
<p>Overall, this file provides a flexible and configurable solution for creating and updating a gating model that can be easily integrated into the Bittensor network.</p>
<h2 id="this-chapter-explains-the-gatingmodel-class-which-is-a-pytorch-module-for-creating-a-gating-model-in-the-bittensor-network-the-main-functions-of-this-module-are"><a class="header" href="#this-chapter-explains-the-gatingmodel-class-which-is-a-pytorch-module-for-creating-a-gating-model-in-the-bittensor-network-the-main-functions-of-this-module-are">This chapter explains the GatingModel class, which is a PyTorch module for creating a gating model in the Bittensor network. The main functions of this module are:</a></h2>
<p>Encoding input messages and generating scores for each unique identifier (uid) in the network.
Running a backward pass through the model using mean squared error between normalized scores and normalized rewards as the loss function.</p>
<h3 id="methods"><a class="header" href="#methods">Methods</a></h3>
<p>• add_args: Adds command line arguments to configure the gating model.
• config: Returns a configuration object containing the command line arguments for the gating model.
• check_config: Validates the configuration object for the gating model.
• init: Initializes the gating model. 
• backward: Runs a backward pass through the model.
• forward: Runs a forward pass through the model, encoding the input message and generating scores for each uid in the network.</p>
<p><code>def add_args(cls, parser: argparse.ArgumentParser)</code></p>
<h3 id="usage"><a class="header" href="#usage">Usage</a></h3>
<p>The module uses a pre-trained transformer-based language model as the encoding layer and a linear layer to generate scores for each uid. The model is optimized using the stochastic gradient descent (SGD) algorithm.</p>
<p>To use the gating model, a user would first create an instance of the GatingModel class with the desired configuration and then run the forward and backward methods for their specific use case.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-summary-of"><a class="header" href="#code-summary-of">Code Summary of</a></h1>
<p><code>_neuron/text/core_validator/__init__.py</code></p>
<p><strong>This Python script defines a class called neuron that acts as a core component in a distributed machine learning network. It is responsible for managing the network communication, the model training, and the reward distribution among peers.</strong> </p>
<h2 id="key-components"><a class="header" href="#key-components">Key Components</a></h2>
<h3 id="constants"><a class="header" href="#constants">Constants</a></h3>
<ul>
<li><code>__default_question_prompt__</code>: The default prompt used for generating questions from the network to evaluate other miners.</li>
<li><code>__default_base_prompt__</code>: The default base prompt injected before a question is completed by miners on the network.</li>
</ul>
<h3 id="class-definition-neuron"><a class="header" href="#class-definition-neuron">Class Definition: neuron</a></h3>
<p>This class is responsible for initializing and managing the network communication, model training, and reward distribution among the peers.</p>
<h4 id="methods-1"><a class="header" href="#methods-1">Methods:</a></h4>
<ul>
<li><code>check_config(cls, config)</code>: Validates the config namespace object and sets up the directories required for logging and reward models.</li>
<li><code>record_event(self, event)</code>: Records a forward event in the history queue and logs the event if specified in the config.</li>
<li><code>add_args(cls, parser)</code>: Adds the command-line arguments required for the neuron configuration.</li>
<li><code>config(cls)</code>: Generates the configuration object using the command-line arguments.</li>
<li><code>__init__(self)</code>: Initializes the neuron instance with the required components like subtensor, wallet, metagraph, tokenizer, reward model, gating model, dendrite pool, history queue, and axon.</li>
</ul>
<h4 id="forward-method"><a class="header" href="#forward-method">Forward Method:</a></h4>
<ul>
<li><code>forward(self, roles, messages, topk, random_sample_uids, train_gating_model, train_network, timeout)</code>: Queries the network for a response to the passed message using a gating model to select the best uids. Trains the gating model based on the rewards calculated for the successful completions and passes rewards backward for potential PPO.</li>
</ul>
<h2 id="execution-flow"><a class="header" href="#execution-flow">Execution Flow</a></h2>
<p>The script initializes a <code>neuron</code> instance and starts the network communication and model training. The neuron class takes care of the communication with other peers in the network and manages the mining process.</p>
<h3 id="additional-methods"><a class="header" href="#additional-methods">Additional Methods</a></h3>
<h4 id="inferenceself-messages-listdictstr-str---str"><a class="header" href="#inferenceself-messages-listdictstr-str---str">inference(self, messages: List[Dict[str, str]]) -&gt; str</a></h4>
<ul>
<li>Logs the inference process.</li>
<li>Pre-processes the messages to extract roles and contents.</li>
<li>Gets scores for the query from the gating model.</li>
<li>Gets uids for the query based on the scores.</li>
<li>Queries the network using the dendrite pool.</li>
<li>Applies the reward model to choose the best completion from the responses.</li>
<li>Returns the best completion.</li>
</ul>
<h4 id="trainself"><a class="header" href="#trainself">train(self)</a></h4>
<ul>
<li>Runs an infinite loop for training.
<ul>
<li>Queries the network for a random question and saves it.</li>
<li>Asks the network to complete the random question while training the gating network.</li>
<li>Syncs the metagraph and updates nominators.</li>
<li>Computes and sets the weights on the blockchain.</li>
</ul>
</li>
</ul>
<h4 id="compute_weightsself---tupletorchlongtensor-torchfloattensor"><a class="header" href="#compute_weightsself---tupletorchlongtensor-torchfloattensor">compute_weights(self) -&gt; Tuple[torch.LongTensor, torch.FloatTensor]</a></h4>
<ul>
<li>Computes the average reward for each uid across non-zero values using the rewards history.</li>
<li>Normalizes the rewards with a softmax and performs a moving average of the normalized rewards.</li>
<li>If the hotkeys have changed, resets the moving averaged scores for the new hotkeys.</li>
<li>Calculates the average reward for each uid across non-zero values.</li>
<li>Processes the raw weights to final_weights via subtensor limitations.</li>
<li>Returns the processed weights and uids.</li>
</ul>
<h3 id="execution-flow-1"><a class="header" href="#execution-flow-1">Execution Flow</a></h3>
<p>When the script is run, it initializes a <code>neuron</code> instance and enters an infinite loop, periodically calling the <code>train()</code> method to train the model and update the weights on the blockchain.</p>
<h1 id="in-conclusion"><a class="header" href="#in-conclusion">In Conclusion,</a></h1>
<p>There's a lot going on here, and I think it's best to investigate yourself, but the goal is to give people the proper tools and knowledge required to build on the network. This knowledge could be quite important depending on what your goals are here. </p>
<div style="break-before: page; page-break-before: always;"></div><p><code>__bittensor/miners/Core Validator.py Analysis__</code></p>
<h3 id="it-is-important-to-note-here-that-i-have-no-idea-about-the-accuracy-of-statements-of-this-and-i-couldnt-explain-what-the-code-actually-does-in-fact-i-didnt-if-it-seems-inaccurate-to-you-then-tell-me-and-i-can-correct-it"><a class="header" href="#it-is-important-to-note-here-that-i-have-no-idea-about-the-accuracy-of-statements-of-this-and-i-couldnt-explain-what-the-code-actually-does-in-fact-i-didnt-if-it-seems-inaccurate-to-you-then-tell-me-and-i-can-correct-it"><em><strong>It is important to note here that I have no idea about the accuracy of statements of this, and I couldn't explain what the code actually does. In fact, I didn't. If it seems inaccurate to you, then tell me and I can correct it.</strong></em></a></h3>
<h2 id="the-code-revolves-around-the-following-concepts"><a class="header" href="#the-code-revolves-around-the-following-concepts">The code revolves around the following concepts:</a></h2>
<blockquote>
<p>Querying multiple machine learning models (endpoints) and aggregating their predictions.
Calculating Shapley values and Shapley synergies to evaluate the contributions of each model in a coalition.
Formatting the predictions and logging results for a better understanding of model performance and interactions.</p>
</blockquote>
<h2 id="the-main-functions-of-the-code-can-be-summarized-as-follows"><a class="header" href="#the-main-functions-of-the-code-can-be-summarized-as-follows">The main functions of the code can be summarized as follows:</a></h2>
<ol>
<li>query function: Sends queries to multiple endpoints (models), collects their responses, and returns the aggregated results along with endpoint statistics.</li>
<li>shapley function: Calculates Shapley values based on endpoint statistics and the loss values of each model in a coalition.</li>
<li>shapley_synergy function: Calculates Shapley synergies for coalitions of size 2, measuring the performance improvement over expected individual model performance.</li>
<li>format_predictions function: Formats the batch task top-k predictions for a rich table print of query responses.</li>
<li>unsuccess function: Prints the return codes and response times of unsuccessful responses.</li>
</ol>
<h2 id="overall-the-purpose-of-this-python-file-is-to-handle-interactions-between-multiple-machine-learning-models-evaluate-their-performance-and-contributions-to-a-coalition-and-format-the-results-for-better-understanding-and-visualization"><a class="header" href="#overall-the-purpose-of-this-python-file-is-to-handle-interactions-between-multiple-machine-learning-models-evaluate-their-performance-and-contributions-to-a-coalition-and-format-the-results-for-better-understanding-and-visualization">Overall, the purpose of this Python file is to handle interactions between multiple machine learning models, evaluate their performance and contributions to a coalition, and format the results for better understanding and visualization.</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="how-rewards-work"><a class="header" href="#how-rewards-work">How Rewards Work</a></h1>
<p>This code defines a <code>RewardModel</code> class that inherits from <code>torch.nn.Module</code>. The <code>RewardModel</code> is used to calculate rewards for completions generated by a language model.</p>
<ol>
<li>
<p><code>__init__</code> method initializes the class with <code>model_path</code>, <code>device</code>, and <code>config</code> as arguments. It loads the pre-trained GPT model and tokenizer from the given model path. It also initializes the linear head <code>v_head</code> and sets the padding token.</p>
</li>
<li>
<p><code>reward</code> method computes rewards for a list of completions. It takes a list of completions and returns a tensor of rewards for each completion.</p>
</li>
<li>
<p><code>forward</code> method computes the forward pass of the model. It takes input tensors such as <code>input_ids</code>, <code>attention_mask</code>, etc., and returns a dictionary containing the loss, chosen end scores, and rejected end scores.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="synopsis-of-bittensor-code"><a class="header" href="#synopsis-of-bittensor-code">Synopsis of Bittensor Code</a></h1>
<p>This module will eventually detail the components of Bittensor, a decentralized AI network. Key components include versioning, rich console setup, functions for controlling the console, constants, and Prometheus setup.</p>
<h2 id="key-components-1"><a class="header" href="#key-components-1">Key Components</a></h2>
<ul>
<li><strong>Versioning</strong>: The code uses semantic versioning with a format like <code>4.0.1</code>.</li>
<li><strong>Rich Console Setup</strong>: The rich console is set up to display output in a more visually appealing manner.</li>
<li><strong>Console Control</strong>: A function <code>turn_console_off</code> is provided to turn off the rich console output.</li>
<li><strong>Constants</strong>: Various constants are defined, such as network dimensions, block time, SS58 format, dataset names, entry points, and network explorer map.</li>
<li><strong>Prometheus Setup</strong>: The code sets up Prometheus for monitoring with a version like <code>0.1.0</code>.</li>
</ul>
<h2 id="example-usage"><a class="header" href="#example-usage">Example Usage</a></h2>
<p>The Bittensor code can be used to create and interact with a decentralized AI network. This includes managing the network components, dataset handling, and communication with the Substrate blockchain.</p>
<p>Please note that the actual implementation details, such as importing required classes and setting up default configurations, have been omitted from this summary for brevity.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-an-epoch"><a class="header" href="#what-is-an-epoch">What is an Epoch?</a></h1>
<h2 id="epochs-in-bittensor-network"><a class="header" href="#epochs-in-bittensor-network">Epochs in Bittensor Network</a></h2>
<p>Epochs in the context of the Bittensor network are used to manage the update and synchronization process of the network's state, including the weights of the neurons (network participants). Each epoch represents a time period during which the network participants train their models, exchange information, and update their local states. At the end of an epoch, the updated weights are submitted to the network, and a new epoch begins.</p>
<p>In Bittensor, the concept of epochs serves several purposes:</p>
<h3 id="1-synchronization"><a class="header" href="#1-synchronization">1. Synchronization</a></h3>
<p>Epochs help synchronize the state of the network. By having a fixed time period during which participants can train their models and exchange information, the network ensures that all nodes have a chance to update their local states before the next epoch begins.</p>
<h3 id="2-weight-updates"><a class="header" href="#2-weight-updates">2. Weight updates</a></h3>
<p>At the end of each epoch, the updated weights are submitted to the network, which helps maintain the global state and improve the overall performance of the network.</p>
<h3 id="3-incentivization"><a class="header" href="#3-incentivization">3. Incentivization</a></h3>
<p>Bittensor uses a staking mechanism to incentivize network participants. By participating in the network and submitting their weights at the end of each epoch, participants can earn rewards in the form of tokens.</p>
<h3 id="4-decentralization"><a class="header" href="#4-decentralization">4. Decentralization</a></h3>
<p>By dividing the network's operation into epochs, Bittensor ensures that no single participant has control over the entire network. This promotes decentralization and helps maintain the network's security and stability.</p>
<p>In summary, epochs in the Bittensor network are used to manage the update process, synchronize the network's state, incentivize participants, and promote decentralization.</p>
<h2 id="function-run_epoch"><a class="header" href="#function-run_epoch">Function: <code>run_epoch</code></a></h2>
<p>The <code>run_epoch</code> function executes a single validator epoch. It applies batches until the epoch length is exhausted. Occasionally, the validator nucleus is reset to ensure it doesn't converge too far. At the end of the epoch, weights are set on the chain and optionally logged to wandb.</p>
<h4 id="code-explanation"><a class="header" href="#code-explanation">Code Explanation</a></h4>
<ol>
<li>
<p>Get parameters for the epoch depending on the selected network (either 'nakamoto' or 'finney'). Parameters include batch_size, sequence_length, prune_len, logits_divergence, min_allowed_weights, max_weight_limit, scaling_law_power, and synergy_scaling_law_power.</p>
</li>
<li>
<p>Update the dataset size based on the calculated batch_size, sequence_length, and validation_len.</p>
</li>
<li>
<p>Run the epoch:
a. Initialize epoch-related variables like epoch_steps, epoch_responsive_uids, epoch_queried_uids, and epoch_start_time.
b. Log the start of the epoch using wandb and prometheus.
c. Run a loop until either the block count or the time limit is reached.
i.   Log the current state of the epoch.
ii.  Perform a forward pass through the network and calculate the loss and endpoint scores.
iii. Perform a backward pass if the loss has a gradient.
iv.  Update neuron stats, responsive_uids, and queried_uids.
v.   Update the state of the epoch, including the global_step and current_block.
vi.  Perform optimization steps.
vii. Log the state of the epoch using console messages, console tables, prometheus, and wandb.
viii.Reset the metagraph.</p>
</li>
<li>
<p>Calculate neuron weights at the end of the epoch.</p>
</li>
<li>
<p>Set weights on the chain using the calculated weights.</p>
</li>
<li>
<p>Log the end of the epoch using console messages, console tables, prometheus, and wandb.</p>
</li>
<li>
<p>Increment the epoch counter.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="miner-template-analysis--"><a class="header" href="#miner-template-analysis--">Miner Template Analysis -</a></h1>
<p>The provided code is a benchmarking superclass for the Bittensor framework. It measures the performance of miners with respect to query execution, allowing for customization and testing of various parameters.</p>
<h2 id="key-components-2"><a class="header" href="#key-components-2">Key Components</a></h2>
<ol>
<li>
<p><strong><strong>init</strong>(self):</strong> Initializes the benchmark background processes and sets up the logging directory.</p>
</li>
<li>
<p><strong>benchmark_config(cls):</strong> Retrieves the configuration from the argument parser.</p>
</li>
<li>
<p><strong>add_args(cls, parser):</strong> Adds command-line arguments for configuration.</p>
</li>
<li>
<p><strong>miner_name():</strong> Returns the miner's name as a string. This method should be implemented in the subclass.</p>
</li>
<li>
<p><strong>run_neuron(config):</strong> This method should be implemented in the subclass to run the neuron using the provided configuration.</p>
</li>
<li>
<p><strong>config():</strong> Returns the configuration object for the miner. This method should be implemented in the subclass.</p>
</li>
<li>
<p><strong>_run_background_process(self, run_neuron_func, config_func):</strong> Initializes the background process by pulling the configuration and starting the subclass static run method.</p>
</li>
<li>
<p><strong>startup(self):</strong> Starts the mining process in the background.</p>
</li>
<li>
<p><strong>shutdown(self):</strong> Terminates the mining process.</p>
</li>
<li>
<p><strong>find_endpoint(self):</strong> Finds the background neuron axon endpoint from the chain.</p>
</li>
<li>
<p><strong>dend_forward(args):</strong> Handles the dendrite request for the multiprocessing case.</p>
</li>
<li>
<p><strong>query_sequence(self, ncalls:int, batch_size:int, block_size:int):</strong> Queries the background neuron with the specified parameters.</p>
</li>
<li>
<p><strong>print_query_analysis(self, history):</strong> Prints the analysis of the query trial.</p>
</li>
<li>
<p><strong>run_standard_benchmark(self):</strong> Runs the default query sizes for benchmarking.</p>
</li>
<li>
<p><strong>run(self):</strong> Executes all methods with the <code>benchmark_</code> prefix.</p>
</li>
</ol>
<h2 id="how-to-use-it"><a class="header" href="#how-to-use-it">How to use it</a></h2>
<p>To create your own benchmark for your miner, you need to subclass <code>QueryBenchmark</code> and implement the <code>miner_name()</code>, <code>run_neuron(config)</code>, and <code>config()</code> methods. Additionally, you can create custom benchmark methods by adding functions with the <code>benchmark_</code> prefix. These functions will be automatically executed when the <code>run()</code> method is called.</p>
<p>Once you've created your custom benchmark class, you can run the benchmarking script and analyze the performance of your miner with different configurations and parameters.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="miner-template-analysis"><a class="header" href="#miner-template-analysis">Miner Template Analysis</a></h1>
<p>The provided code is a miner template for benchmarking using the Bittensor framework. It's designed to be a starting point for creating a custom miner, and measures its performance with respect to query execution. The template extends the <code>QueryBenchmark</code> class and provides methods for running the miner and configuring it.</p>
<h2 id="what-it-does"><a class="header" href="#what-it-does">What it does</a></h2>
<ol>
<li>
<p><strong>miner_name():</strong> This method returns the miner's name as a string, which is set to 'template_miner' in this case.</p>
</li>
<li>
<p><strong>run_neuron(config):</strong> This method takes a Bittensor configuration object as input and runs the neuron using the <code>template_miner</code> implementation.</p>
</li>
<li>
<p><strong>config():</strong> This method returns the configuration object for the miner.</p>
</li>
<li>
<p><strong>benchmark_custom():</strong> This method runs the custom benchmark by performing a sequence of queries with a specified number of calls, batch size, and block size. It then prints the query analysis and saves the results to a CSV file.</p>
</li>
<li>
<p>The <code>main</code> function initializes a <code>Benchmark</code> object and runs the benchmark.</p>
</li>
</ol>
<h2 id="adapting-the-template-to-your-own-miner"><a class="header" href="#adapting-the-template-to-your-own-miner">Adapting the template to your own miner</a></h2>
<p>To adapt this template to your own miner, you need to make the following changes:</p>
<ol>
<li>
<p>Update the <code>miner_name()</code> method to return your custom miner's name.</p>
</li>
<li>
<p>Modify the <code>run_neuron(config)</code> method to use your custom miner's neuron implementation. Replace <code>bittensor.neurons.text.template_miner.neuron</code> with your own miner's neuron class.</p>
</li>
<li>
<p>Update the <code>config()</code> method to return the configuration object for your custom miner. Replace <code>bittensor.neurons.text.template_miner.neuron.config()</code> with the configuration method for your miner's neuron class.</p>
</li>
<li>
<p>Customize the <code>benchmark_custom()</code> method if you have specific benchmarking requirements. You can modify the number of calls, batch size, and block size, or implement additional benchmarking tests.</p>
</li>
<li>
<p>If your custom miner requires additional configuration or setup, you can add those steps in the <code>main</code> function or in a separate method.</p>
</li>
</ol>
<p>After making these changes, you can run the benchmarking script for your custom miner and analyze its performance.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cuda-pow"><a class="header" href="#cuda-pow">Cuda PoW</a></h1>
<p>Bittensor uses Cuda. I swear I analyzed a file, I'll get back around to it. </p>
<div style="break-before: page; page-break-before: always;"></div><p><code>Interpreted from bittensor/bittensor/_keyfile/keyfile_impl.py</code></p>
<h1 id="keyfile-and-mockkeyfile-overview"><a class="header" href="#keyfile-and-mockkeyfile-overview">Keyfile and MockKeyfile Overview</a></h1>
<p>This code defines two classes, <code>Keyfile</code> and <code>MockKeyfile</code>, which are responsible for handling keyfile operations for the Bittensor project. These classes provide methods for creating, reading, writing, encrypting, and decrypting keyfiles, as well as managing their respective keypairs.</p>
<h2 id="keyfile-class"><a class="header" href="#keyfile-class">Keyfile Class</a></h2>
<p>The <code>Keyfile</code> class is designed to manage keyfiles on the device. Key methods include:</p>
<ul>
<li>Creating and initializing a new keyfile.</li>
<li>Reading and writing keyfile data to the file system.</li>
<li>Encrypting and decrypting keyfiles with a password.</li>
<li>Checking if a keyfile exists, is readable, writable, or encrypted.</li>
</ul>
<h2 id="mockkeyfile-class"><a class="header" href="#mockkeyfile-class">MockKeyfile Class</a></h2>
<p>The <code>MockKeyfile</code> class provides an interface for a mocked keyfile object that does not interact with the device's file system. It is useful for testing and development purposes. The keypair is treated as non-encrypted, and the data is stored as a string.</p>
<p>Key methods include:</p>
<ul>
<li>Initializing a new mock keyfile.</li>
<li>Returning the mock keypair and keyfile data.</li>
<li>Setting a new keypair in the mock keyfile.</li>
<li>Providing dummy methods for file operations, such as checking if the file exists, is readable, writable, or encrypted.</li>
</ul>
<p>By using the <code>Keyfile</code> and <code>MockKeyfile</code> classes, developers can easily manage keyfiles and their associated keypairs, ensuring proper encryption and access control for secure Bittensor operations.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="genesistextdataset"><a class="header" href="#genesistextdataset">GenesisTextDataset</a></h1>
<h2 id="this-is-a-summary-of-functions-found-within--"><a class="header" href="#this-is-a-summary-of-functions-found-within--">This is a summary of Functions found within -</a></h2>
<p><code>bittensor/bittensor/_dataset/dataset_impl.py</code></p>
<h2 id="to-give-a-high-level-overview-of-what-this-script-does"><a class="header" href="#to-give-a-high-level-overview-of-what-this-script-does"><strong>To give a high level overview of what this script does:</strong></a></h2>
<p><code>GenesisTextDataset</code> is a class designed to handle text datasets for training language models. It uses IPFS (InterPlanetary File System) as a source for the text data and allows the user to load data from IPFS or a local directory. It provides methods to create a PyTorch DataLoader, reserve text data, and update the data size.</p>
<h2 id="key-functions"><a class="header" href="#key-functions">Key Functions</a></h2>
<h3 id="construct_text_corpus"><a class="header" href="#construct_text_corpus">construct_text_corpus</a></h3>
<p>This function generates the text data by getting directories from a random dataset hash and picking a random directory to get the text from. It repeats this process until the minimum data length is reached.</p>
<h3 id="reserve_multiple_data"><a class="header" href="#reserve_multiple_data">reserve_multiple_data</a></h3>
<p>This function reserves the data to ensure that it meets the specified multiple of the dataset size. If not, it keeps constructing text corpus until the required size is met.</p>
<h3 id="set_data_size"><a class="header" href="#set_data_size">set_data_size</a></h3>
<p>This function updates the size of data (batch_size, block_size) required for the DataLoader.</p>
<h3 id="dataloader"><a class="header" href="#dataloader">dataloader</a></h3>
<p>This function creates a PyTorch DataLoader from a subclass of this class, using the reserved data and the specified data size.</p>
<h3 id="set_dataset_iterator"><a class="header" href="#set_dataset_iterator">set_dataset_iterator</a></h3>
<p>This function gets a new dataset from the data queue and updates the <code>__infinite_dataset_iterator__</code> attribute.</p>
<h3 id="next"><a class="header" href="#next"><strong>next</strong></a></h3>
<p>This method returns the next element from the dataset.</p>
<h3 id="len"><a class="header" href="#len"><strong>len</strong></a></h3>
<p>This method returns the number of samples (blocks) of the dataset.</p>
<h3 id="getitem"><a class="header" href="#getitem"><strong>getitem</strong></a></h3>
<p>This method returns a block of sentences from the text dataset at a given index.</p>
<h3 id="build_hash_table"><a class="header" href="#build_hash_table">build_hash_table</a></h3>
<p>This function builds a hash table with dataset hashes and metadata.</p>
<h2 id="dataset-class"><a class="header" href="#dataset-class">Dataset class</a></h2>
<p>Implements a dataset class that handles data loading from IPFS. Key methods include:</p>
<ul>
<li>
<p><code>requests_retry_session</code>: Creates a retriable session for request calls, enabling automatic retries and back-off retries should any request calls fail.</p>
</li>
<li>
<p><code>get_ipfs_directory</code>: Connects to IPFS gateway and retrieves a directory, returning a dictionary of the files inside of the genesis_datasets and their hashes.</p>
</li>
<li>
<p><code>__len__</code>: Returns the length of the dataset that the dataset is processing.</p>
</li>
<li>
<p><code>__getitem__</code>: Returns the next batch from the dataset.</p>
</li>
</ul>
<h2 id="genesistextdataset-class"><a class="header" href="#genesistextdataset-class">GenesisTextDataset class</a></h2>
<p>Inherits from the Dataset class and caters for data from IPFS. Key features include:</p>
<ul>
<li>
<p><strong>Initialization</strong>: Initializes important attributes like block_size, batch_size, num_workers, tokenizer, dataset_names, data_dir, save_dataset, and others.</p>
</li>
<li>
<p>Ensures dataset_names is formatted correctly, removing invalid datasets.</p>
</li>
<li>
<p>Retrieves a random slice of the genesis dataset.</p>
</li>
<li>
<p>Builds a hash table.</p>
</li>
<li>
<p>Creates a ThreadQueue instance for a data queue, which reserves multiple data in batches.</p>
</li>
<li>
<p><code>__del__</code> and <code>close</code>: Close the data queue.</p>
</li>
<li>
<p><code>get_folder_size</code>: Get the size (in bytes) of a folder inside the data_dir.</p>
</li>
<li>
<p><code>load_hash</code>: Load a hash from disk, returning the text in the file.</p>
</li>
<li>
<p><code>save_hash</code>: Save a hash to disk, taking a file_meta dictionary and text as input.</p>
</li>
<li>
<p><code>get_text</code>: Either load a file from disk or download it from IPFS, returning the text from the file.</p>
</li>
<li>
<p><code>get_dataset</code>: Either load a dataset (a list of hashes) from disk or download it from IPFS.</p>
</li>
<li>
<p><code>get_hashes_from_dataset</code>: Get directories, where a directory could lead to a data file or a directory file, returning a list of directories (random directory that leads to a data file).</p>
</li>
<li>
<p><code>get_root_text_hash</code>: With recursion, get a random directory that leads to a data file from the given directory.</p>
</li>
<li>
<p><code>get_text_from_local</code>: Load text data from the local data directory, returning a list of text data.</p>
</li>
<li>
<p><code>construct_text_corpus</code>: Main function for generating the text data, returning the text corpus.</p>
</li>
<li>
<p><code>reserve_multiple_data</code>: Make sure the reserved data meet the given multiples. If not, keep constructing the text corpus.</p>
</li>
<li>
<p><code>set_data_size</code>: Update the size of data (batch_size, block_size) that is needed.</p>
</li>
<li>
<p><code>dataloader</code>: Creates a torch dataloader out of a subclass of this class.</p>
</li>
<li>
<p><code>set_dataset_iterator</code>: Get a new dataset that is ready from the queue. The result is updated to <code>self.__infinite_dataset_iterator__</code>.</p>
</li>
<li>
<p><code>__next__</code>: Returns the next element from the dataset.</p>
</li>
<li>
<p><code>__len__</code>: Returns the number of samples (blocks) of the dataset.</p>
</li>
<li>
<p><code>__getitem__</code>: Returns a block of sentences from the text dataset.</p>
</li>
<li>
<p><code>build_hash_table</code>: Builds a hash table containing dataset hashes.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><p><code>/bittensor/bittensor/_dataset/MockGenesisTextDataset.py</code></p>
<h2 id="class-mockgenesistextdataset"><a class="header" href="#class-mockgenesistextdataset">Class: MockGenesisTextDataset</a></h2>
<p><code>MockGenesisTextDataset</code> is a subclass of <code>dataset_impl.Dataset</code>. It provides functionalities for creating a mock text dataset for testing purposes.</p>
<h3 id="methods-2"><a class="header" href="#methods-2">Methods:</a></h3>
<ul>
<li><code>__init__(self, block_size, batch_size, num_workers, dataset_names, data_dir, save_dataset, max_datasets, no_tokenizer, num_batches)</code>: Initializes the class with parameters.</li>
<li><code>close(self)</code>: Closes the dataset.</li>
<li><code>construct_text_corpus(self, min_data_len)</code>: Constructs a text corpus of a given minimum length using a fixed placeholder text.</li>
<li><code>_fill_data(self, epoch_length)</code>: Fills the data with a specified epoch_length.</li>
<li><code>dataloader(self, epoch_length)</code>: Creates a torch dataloader from a subclass of this class.</li>
<li><code>__next__(self)</code>: Returns the next element from the dataset.</li>
<li><code>__len__(self)</code>: Returns the number of samples (blocks) in the dataset.</li>
<li><code>__getitem__(self, idx)</code>: Returns a block of sentences from the text dataset based on the given index.</li>
</ul>
<h1 id="but-what-does-this-mean"><a class="header" href="#but-what-does-this-mean">But what does this mean?</a></h1>
<p>Guess you'll have to figure it out. </p>
<div style="break-before: page; page-break-before: always;"></div><p><code>bittensor/bittensor/_logging/__init__.py</code></p>
<h1 id="bittensor-logging-overview"><a class="header" href="#bittensor-logging-overview">Bittensor Logging Overview</a></h1>
<p>The following code block defines a <code>logging</code> class for Bittensor that standardizes the logging process. The class supports setting logging levels, customizing log messages, and sinking logs to files for storage.</p>
<h1 id="introduction-to-logging-in-bittensor"><a class="header" href="#introduction-to-logging-in-bittensor">Introduction to Logging in Bittensor</a></h1>
<p>Bittensor is a distributed machine learning framework that leverages blockchain technology. It provides a decentralized platform for training AI models in a collaborative manner. One of the essential aspects of any software system is the logging mechanism, and Bittensor is no exception. Logging helps developers monitor the system's behavior, track errors, and debug issues efficiently.</p>
<p>In Bittensor, logging is implemented using a customized version of the Loguru library. Loguru is a powerful and flexible logging library for Python that offers simplicity, performance, and reliability. Bittensor's logging mechanism is designed to provide a standardized and structured approach to logging throughout the system, ensuring that log messages are consistent, readable, and maintainable.</p>
<p>The logging system in Bittensor consists of several class methods responsible for formatting, filtering, and logging messages. These methods are organized into a custom logger class, which is then used throughout the Bittensor library to generate log messages. Key features of the Bittensor logging mechanism include:</p>
<ol>
<li>
<p><strong>Custom Formatters</strong>: Bittensor's logging mechanism provides custom formatters for both terminal display and file output. This allows for a consistent log format that can be customized based on the needs of the developer or the specific situation.</p>
</li>
<li>
<p><strong>Conditional Formatting</strong>: The logging system adjusts the formatting of log messages based on specific keys in the record's 'extra' field, such as 'rpc' and 'receptor'. This allows for more informative log messages and helps developers quickly understand the context of each log entry.</p>
</li>
<li>
<p><strong>Log Levels</strong>: Bittensor's logging mechanism supports various log levels, including success, warning, error, and info. These log levels help developers filter log messages and focus on the most relevant information for their needs.</p>
</li>
<li>
<p><strong>Trace Information</strong>: When enabled, the logging system can include trace information in log messages, such as the function name and line number. This can be useful for debugging purposes and for understanding the flow of execution within the system.</p>
</li>
</ol>
<p>By leveraging the power and flexibility of Loguru, Bittensor's logging mechanism provides a robust and user-friendly way to monitor and debug the distributed machine learning system. With a standardized approach to logging, developers can easily understand the system's behavior and quickly identify and resolve issues.</p>
<h2 id="logging-class"><a class="header" href="#logging-class">Logging Class</a></h2>
<p>The <code>logging</code> class provides methods to manage Bittensor's logging system. The key aspects of the class are:</p>
<ul>
<li>Instantiating the logging system with various configuration options.</li>
<li>Adding and removing log sinks.</li>
<li>Filtering logs based on the chosen logging level (debug, trace, etc.).</li>
<li>Saving logs to files with log rotation and retention.</li>
<li>Providing helper methods for configuration and debugging.</li>
</ul>
<h3 id="instantiating-logging"><a class="header" href="#instantiating-logging">Instantiating Logging</a></h3>
<p>The <code>__new__()</code> method initializes the logging system with various options such as:</p>
<ul>
<li>Enabling or disabling debugging and trace information.</li>
<li>Turning on or off logging to a file.</li>
<li>Specifying the directory where logs are saved.</li>
</ul>
<h3 id="adding-and-removing-log-sinks"><a class="header" href="#adding-and-removing-log-sinks">Adding and Removing Log Sinks</a></h3>
<p>The class manages log sinks, which determine where log messages are sent. The <code>__std_sink__</code> sends log messages to <code>sys.stdout</code>, while <code>__file_sink__</code> sinks logs to a file. The class also provides methods to remove existing sinks.</p>
<h3 id="log-filtering"><a class="header" href="#log-filtering">Log Filtering</a></h3>
<p>The <code>log_filter()</code> and <code>log_save_filter()</code> methods are used to filter logs based on the current logging level (debug or trace). This helps control the verbosity of log messages displayed or saved.</p>
<h3 id="configuration-and-helper-methods"><a class="header" href="#configuration-and-helper-methods">Configuration and Helper Methods</a></h3>
<p>The class provides several methods to handle configuration and debugging:</p>
<ul>
<li><code>config()</code>: Retrieves the config object from the argument parser.</li>
<li><code>help()</code>: Prints help information to stdout.</li>
<li><code>add_args()</code>: Adds arguments to the argument parser for logging configuration.</li>
<li><code>add_defaults()</code>: Sets default values for the logging configuration based on environment variables.</li>
<li><code>check_config()</code>: Checks the validity of the given config object.</li>
<li><code>set_debug()</code>: Enables or disables the debug logging level.</li>
<li><code>set_trace()</code>: Enables or disables the trace logging level.</li>
</ul>
<p>With the <code>logging</code> class, developers can easily manage the logging system for Bittensor, ensuring consistent logging output and behavior across different parts of the project.</p>
<h1 id="bittensor-logging-formatting-and-functions"><a class="header" href="#bittensor-logging-formatting-and-functions">Bittensor Logging Formatting and Functions</a></h1>
<p>This code block consists of several class methods responsible for the formatting, filtering, and logging of messages in the bittensor library. It provides a standardized approach to logging throughout the system, helping to improve the readability and maintainability of the code.</p>
<h2 id="log-formatter-methods"><a class="header" href="#log-formatter-methods">Log Formatter Methods</a></h2>
<ol>
<li>
<p><strong>log_formatter</strong>: This method formats the log messages for display in the terminal. It customizes the log format based on the presence of specific keys in the record's 'extra' field, such as 'rpc' and 'receptor'. It also considers the 'trace_on' flag to determine whether to include trace information or not.</p>
</li>
<li>
<p><strong>log_save_formatter</strong>: Similar to the log_formatter method, this method formats log messages for saving to a file. It also adjusts the formatting based on the presence of specific keys in the record's 'extra' field and the 'trace_on' flag.</p>
</li>
</ol>
<h2 id="logging-utility-methods"><a class="header" href="#logging-utility-methods">Logging Utility Methods</a></h2>
<ol>
<li>
<p><strong>rpc_log</strong>: This method logs information about communication between endpoints (axon and dendrite) during the forward or backward pass. It provides essential details such as the call time, public key, unique identifier (uid), inputs, outputs, messages, and synapse.</p>
</li>
<li>
<p><strong>update_receptor_log</strong>: This method logs details about updating connections with a given endpoint. It includes information such as uid, hotkey, coldkey, and IP address.</p>
</li>
<li>
<p><strong>success</strong>, <strong>warning</strong>, <strong>error</strong>, and <strong>info</strong>: These methods are responsible for logging messages with various log levels (success, warning, error, and info). Each method ensures that the logging prefix is left-justified and followed by the log message.</p>
</li>
</ol>
<p>The code block offers a structured and standardized way of logging information in the bittensor library, making it easier for developers to understand the system's behavior and debug issues.</p>
<div style="break-before: page; page-break-before: always;"></div><p><code>bittensor/bittensor/_metagraph/metagraph_impl.py</code></p>
<h1 id="metagraph-class-overview"><a class="header" href="#metagraph-class-overview">Metagraph Class Overview</a></h1>
<p>The <code>Metagraph</code> class is a subclass of <code>torch.nn.Module</code> that maintains chain state.
The Metagraph class provides a representation of the Bittensor metagraph.
<code>/bittensor/bittensor/_metagraph/__init__.py</code> 
<strong>If I am not mistaken, this .py script initiates the metagraph_impl.py file.</strong> </p>
<h2 id="properties"><a class="header" href="#properties">Properties</a></h2>
<ul>
<li>Basic properties: version, n, tau, block, uids, stake, total_stake</li>
<li>Rank-related properties: ranks, trust, consensus, validator_trust, incentive, emission, dividends</li>
<li>Other properties: active, last_update, validator_permit, weights, bonds, endpoints, addresses, endpoint_objs</li>
</ul>
<h2 id="methods-3"><a class="header" href="#methods-3">Methods</a></h2>
<ul>
<li>Initialization and update methods: <strong>init</strong>, from_tensor, update</li>
<li>Getter methods: getitem, get, uid_to_hotkey, hotkey_to_uid</li>
<li>Persistence methods: load, save, load_from_path, save_to_path, load_from_state_dict</li>
<li>Syncing method: sync</li>
<li>Data export methods: to_dataframe, to_wandb</li>
<li>String representation methods: <strong>str</strong>, <strong>repr</strong></li>
</ul>
<h3 id="properties-1"><a class="header" href="#properties-1">Properties</a></h3>
<ul>
<li><strong>tau</strong>: Current, per block, token emission rate.</li>
<li><strong>block</strong>: State block number.</li>
<li><strong>uids</strong>: UIDs for each neuron.</li>
<li><strong>stake</strong>: Stake balance for each neuron ordered by uid.</li>
<li><strong>last_update</strong>: Last emission call for each neuron ordered by uid.</li>
<li><strong>weights</strong>: Full weight matrix on chain ordered by uid.</li>
<li><strong>neurons</strong>: Tokenized endpoint information.</li>
</ul>
<h3 id="methods-4"><a class="header" href="#methods-4">Methods</a></h3>
<ul>
<li><strong><strong>init</strong></strong>: Initializes a new Metagraph torch chain interface object.</li>
<li><strong><strong>info_state_dict_hook</strong></strong>: Hook for state_dict to add info to state_dict, e.g., before saving.</li>
<li><strong>clear</strong>: Erases Metagraph state.</li>
</ul>
<h3 id="properties-derived"><a class="header" href="#properties-derived">Properties (Derived)</a></h3>
<ul>
<li><strong>S</strong>: Stake</li>
<li><strong>R</strong>: Rank</li>
<li><strong>I</strong>: Incentive</li>
<li><strong>E</strong>: Emission</li>
<li><strong>C</strong>: Consensus</li>
<li><strong>T</strong>: Trust</li>
<li><strong>Tv</strong>: Validator trust</li>
<li><strong>D</strong>: Dividends</li>
<li><strong>B</strong>: Bonds</li>
<li><strong>W</strong>: Weights</li>
<li><strong>hotkeys</strong>: Returns hotkeys for each neuron.</li>
<li><strong>coldkeys</strong>: Returns coldkeys for each neuron.</li>
<li><strong>modalities</strong>: Returns the modality for each neuron.</li>
</ul>
<h3 id="properties-2"><a class="header" href="#properties-2">Properties</a></h3>
<ul>
<li><strong>addresses</strong>: Returns IP addresses for each endpoint.</li>
<li><strong>endpoint_objs</strong>: Returns endpoints as objects.</li>
</ul>
<h3 id="methods-5"><a class="header" href="#methods-5">Methods</a></h3>
<ul>
<li><strong>hotkey_to_uid</strong>: Fetches the UID according to the hotkey.</li>
<li><strong>load</strong>: Loads the metagraph object's state_dict from Bittensor root directory.</li>
<li><strong>save</strong>: Saves the metagraph object's state_dict under Bittensor root directory.</li>
<li><strong>load_from_path</strong>: Loads the metagraph object with state_dict under the specified path.</li>
<li><strong>save_to_path</strong>: Saves the metagraph object's state_dict to the specified path.</li>
<li><strong>load_from_state_dict</strong>: Loads the metagraph object from the passed state_dict.</li>
<li><strong>sync</strong>: Synchronizes the metagraph with the chain state.</li>
<li><strong>to_dataframe</strong>: Converts the metagraph data to a pandas DataFrame.</li>
<li><strong>to_wandb</strong>: Returns metagraph information as a dictionary for Weights &amp; Biases logging.</li>
<li><strong><strong>str</strong></strong>: Returns a string representation of the Metagraph object.</li>
<li><strong><strong>repr</strong></strong>: Returns the string representation of the Metagraph object (same as <code>__str__</code>).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ip-address-utility-script---bittensorbittensorutilsnetworkingpy"><a class="header" href="#ip-address-utility-script---bittensorbittensorutilsnetworkingpy">IP Address Utility Script - <code>bittensor/bittensor/utils/networking.py</code></a></h1>
<p>This script provides a set of utility functions to help you work with IP addresses, automatically detect your external IP address, set up port forwarding using the Universal Plug and Play (UPnP) protocol, and format WebSocket URLs. It is designed to simplify common networking tasks for users without extensive knowledge in networking.</p>
<h2 id="key-functions-1"><a class="header" href="#key-functions-1">Key Functions</a></h2>
<ol>
<li>
<p><strong>IP address conversion</strong>: Convert IP addresses between their string and integer representations.</p>
<ul>
<li><code>int_to_ip(int_val: int) -&gt; str</code>: Converts an integer to an IP address string.</li>
<li><code>ip_to_int(str_val: str) -&gt; int</code>: Converts an IP address string to an integer.</li>
</ul>
</li>
<li>
<p><strong>IP version detection</strong>: Determine if a given IP address is IPv4 or IPv6.</p>
<ul>
<li><code>ip_version(str_val: str) -&gt; int</code>: Returns the IP version (4 or 6) of a given IP address string.</li>
</ul>
</li>
<li>
<p><strong>Formatted IP string</strong>: Create a formatted IP string including the IP type, IP address, and port.</p>
<ul>
<li><code>ip__str__(ip_type:int, ip_str:str, port:int)</code>: Returns a formatted IP string.</li>
</ul>
</li>
<li>
<p><strong>External IP address detection</strong>: Automatically find your router's external IP address using various methods.</p>
<ul>
<li><code>get_external_ip() -&gt; str</code>: Tries multiple methods to obtain the external IP address of the router and returns it as a string.</li>
</ul>
</li>
<li>
<p><strong>UPnP port mapping</strong>: Set up port forwarding on your router using the UPnP protocol.</p>
<ul>
<li><code>upnpc_create_port_map(port: int)</code>: Creates a UPnP port map on the router from the provided external port to the local port.</li>
</ul>
</li>
<li>
<p><strong>WebSocket URL formatting</strong>: Format WebSocket URLs for proper use in applications.</p>
<ul>
<li><code>get_formatted_ws_endpoint_url(endpoint_url: str) -&gt; str</code>: Returns a formatted WebSocket endpoint URL.</li>
</ul>
</li>
</ol>
<h2 id="custom-exceptions"><a class="header" href="#custom-exceptions">Custom Exceptions</a></h2>
<p>The script defines two custom exception classes that are raised when specific issues occur:</p>
<ol>
<li><code>ExternalIPNotFound</code>: Raised when the script cannot find the external IP address using any of the available methods.</li>
<li><code>UPNPCException</code>: Raised when there are issues with UPnP port mapping, such as when UPnP is not enabled on the router.</li>
</ol>
<p>By using this script, users who are not well-versed in networking can easily perform tasks related to IP addresses and networking without diving deep into the technical details.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="synopsis-of-whats-going-on-with"><a class="header" href="#synopsis-of-whats-going-on-with">Synopsis of what's going on with</a></h2>
<p><code>bittensor/bittensor/_neuron/text/core_validator/__init__.py</code></p>
<p><strong>Author's note because this file had probably one of the more complex scripts, with many more characters, I did my best to translate between myself and my AI assistant. Some words are mine, and I make edits, but I don't know what's going on down there. Validators are the core of the network, and if you've reached the ability to comprehend how to run a Validator, congratulations.</strong></p>
<h1 id="proof-of-work-solver"><a class="header" href="#proof-of-work-solver">Proof of Work Solver</a></h1>
<p>This script contains a set of classes and functions to perform a proof of work (PoW) computation for the registration process in a distributed network.</p>
<h1 id="bittensor-proof-of-work-registration-with-cuda"><a class="header" href="#bittensor-proof-of-work-registration-with-cuda">Bittensor Proof of Work Registration with CUDA</a></h1>
<p>This document presents a <strong>Python module</strong> for creating a <em>Proof of Work (PoW)</em> registration for a given subtensor and wallet in a Bittensor network. The module leverages <strong>CUDA (Compute Unified Device Architecture)</strong> to speed up the registration process using parallel computing on NVIDIA GPUs.</p>
<p>The module contains:</p>
<ul>
<li>
<p><strong>_solve_for_difficulty_fast_cuda()</strong>: A function that solves the registration using CUDA. It takes several arguments like subtensor, wallet, netuid, output_in_place, update_interval, TPB, dev_id, n_samples, alpha_, and log_verbose. It calculates the hash rate as an exponentially weighted moving average for robustness.</p>
</li>
<li>
<p><strong>_terminate_workers_and_wait_for_exit()</strong>: A function that terminates and waits for all worker processes to exit.</p>
</li>
<li>
<p><strong>create_pow()</strong>: A function that creates a proof of work for the given subtensor and wallet. It takes arguments like subtensor, wallet, netuid, output_in_place, cuda, dev_id, tpb, num_processes, update_interval, and log_verbose. It returns the proof of work solution or None if the wallet is already registered or there's a different error.</p>
</li>
</ul>
<h2 id="classes"><a class="header" href="#classes">Classes</a></h2>
<ol>
<li>
<p><strong>CUDAException</strong>: A custom exception raised when an error occurs in the CUDA environment.</p>
</li>
<li>
<p><strong>POWSolution</strong>: A data class representing a solution to the registration PoW problem.</p>
<ul>
<li><code>is_stale(subtensor: 'bittensor.Subtensor') -&gt; bool</code>: Returns True if the PoW is stale (the block it is solved for is within 3 blocks of the current block).</li>
</ul>
</li>
<li>
<p><strong>_SolverBase</strong>: An abstract base class for a multiprocessing process that solves the registration PoW problem.</p>
</li>
<li>
<p><strong>_Solver</strong>: A subclass of _SolverBase that implements the <code>run</code> method for solving the PoW problem.</p>
</li>
</ol>
<h2 id="functions-2"><a class="header" href="#functions-2">Functions</a></h2>
<ol>
<li>
<p><code>_hex_bytes_to_u8_list(hex_bytes: bytes)</code>: Converts a hexadecimal byte string to a list of unsigned 8-bit integers.</p>
</li>
<li>
<p><code>_create_seal_hash(block_and_hotkey_hash_bytes: bytes, nonce:int) -&gt; bytes</code>: Creates a seal hash based on the given block and hotkey hash bytes and a nonce.</p>
</li>
<li>
<p><code>_seal_meets_difficulty(seal: bytes, difficulty: int, limit: int)</code>: Checks if a seal meets the required difficulty.</p>
</li>
<li>
<p><code>_SolverBase.create_shared_memory() -&gt; Tuple[multiprocessing.Array, multiprocessing.Value, multiprocessing.Array]</code>: Creates shared memory for the solver processes to use.</p>
</li>
<li>
<p><code>_solve_for_nonce_block(nonce_start: int, nonce_end: int, block_and_hotkey_hash_bytes: bytes, block_difficulty: int, limit: int, block_number: int) -&gt; Optional[POWSolution]</code>: Attempts to solve the PoW problem for a range of nonces, returning a solution if successful.</p>
</li>
</ol>
<h2 id="usage-1"><a class="header" href="#usage-1">Usage</a></h2>
<p>The script is designed to perform PoW computation in a multiprocessing environment. The _Solver class can be instantiated with the necessary shared memory, queues, and events for parallel processing. The <code>run</code> method of the _Solver class will continuously attempt to solve the PoW problem and communicate with the main process to receive updates on the current block and difficulty.</p>
<p>By using this script, developers can efficiently perform PoW computations for the registration process in a distributed network.</p>
<h2 id="cudasolver-class"><a class="header" href="#cudasolver-class">CUDASolver Class</a></h2>
<p>The <code>_CUDASolver</code> class is a subclass of <code>_SolverBase</code> and is used for solving the proof of work (POW) on a CUDA device. It takes the following parameters:</p>
<ul>
<li><code>dev_id</code>: ID of the CUDA device</li>
<li><code>TPB</code>: Thread-per-block count</li>
</ul>
<h3 id="methods-6"><a class="header" href="#methods-6">Methods</a></h3>
<ul>
<li><code>__init__()</code>: Initializes the CUDASolver with the given parameters.</li>
<li><code>run()</code>: Executes the solver on a CUDA device.</li>
</ul>
<h2 id="functions-3"><a class="header" href="#functions-3">Functions</a></h2>
<ul>
<li><code>_solve_for_nonce_block_cuda()</code>: Tries to solve the POW on a CUDA device for a block of nonces.</li>
<li><code>_solve_for_nonce_block()</code>: Tries to solve the POW for a block of nonces.</li>
<li><code>_registration_diff_unpack()</code>: Unpacks the packed two 32-bit integers into one 64-bit integer (little endian).</li>
<li><code>_registration_diff_pack()</code>: Packs the difficulty into two 32-bit integers (little endian).</li>
<li><code>_hash_block_with_hotkey()</code>: Hashes the block with the hotkey using Keccak-256 to get 32 bytes.</li>
<li><code>_update_curr_block()</code>: Updates the current block.</li>
</ul>
<h2 id="helper-functions"><a class="header" href="#helper-functions">Helper Functions</a></h2>
<ul>
<li><code>get_cpu_count()</code>: Returns the CPU count.</li>
</ul>
<h2 id="classes-1"><a class="header" href="#classes-1">Classes</a></h2>
<ul>
<li><code>RegistrationStatistics</code>: Data class to store the statistics for a registration.</li>
<li><code>RegistrationStatisticsLogger</code>: Logs statistics for a registration. Provides methods to start, stop, and update the statistics.</li>
</ul>
<h3 id="methods-7"><a class="header" href="#methods-7">Methods</a></h3>
<ul>
<li><code>start()</code>: Starts the status logger.</li>
<li><code>stop()</code>: Stops the status logger.</li>
<li><code>get_status_message()</code>: Returns a formatted status message.</li>
<li><code>update()</code>: Updates the registration statistics.</li>
</ul>
<h2 id="functions-4"><a class="header" href="#functions-4">Functions</a></h2>
<h3 id="_solve_for_difficulty_fast"><a class="header" href="#_solve_for_difficulty_fast">_solve_for_difficulty_fast()</a></h3>
<p>Solves the proof of work (POW) for registration using multiprocessing.</p>
<ul>
<li><code>subtensor</code></li>
<li><code>wallet</code>: Wallet to use for registration.</li>
<li><code>netuid</code>: The netuid of the subnet to register to.</li>
<li><code>output_in_place</code>: If true, prints the status in place. Otherwise, prints the status on a new line.</li>
<li><code>num_processes</code>: Number of processes to use.</li>
<li><code>update_interval</code>: Number of nonces to solve before updating block information.</li>
<li><code>n_samples</code>: The number of samples of the hash_rate to keep for the EWMA.</li>
<li><code>alpha_</code>: The alpha for the EWMA for the hash_rate calculation.</li>
<li><code>log_verbose</code>: If true, prints more verbose logging of the registration metrics.</li>
</ul>
<h3 id="_get_block_with_retry"><a class="header" href="#_get_block_with_retry">_get_block_with_retry()</a></h3>
<p>Gets the current block number, difficulty, and block hash from the substrate node with retry logic.</p>
<ul>
<li><code>subtensor</code>: The subtensor object to use to get the block number, difficulty, and block hash.</li>
<li><code>netuid</code>: The netuid of the network to get the block number, difficulty, and block hash from.</li>
</ul>
<h3 id="_usingspawnstartmethod"><a class="header" href="#_usingspawnstartmethod">_UsingSpawnStartMethod</a></h3>
<p>Context manager for switching the multiprocessing start method to 'spawn' temporarily.</p>
<ul>
<li><code>force</code>: If true, force the start method to be set to 'spawn'.</li>
</ul>
<h3 id="_check_for_newest_block_and_update"><a class="header" href="#_check_for_newest_block_and_update">_check_for_newest_block_and_update()</a></h3>
<p>Checks for a new block and updates the current block information if a new block is found.</p>
<ul>
<li><code>subtensor</code>: The subtensor object to use for getting the current block.</li>
<li><code>netuid</code>: The netuid to use for retrieving the difficulty.</li>
<li><code>old_block_number</code>: The old block number to check against.</li>
<li><code>hotkey_bytes</code>: The bytes of the hotkey's pubkey.</li>
<li><code>curr_diff</code>: The current difficulty as a multiprocessing array.</li>
<li><code>curr_block</code>: Where the current block is stored as a multiprocessing array.</li>
<li><code>curr_block_num</code>: Where the current block number is stored as a multiprocessing value.</li>
<li><code>update_curr_block</code>: A function that updates the current block.</li>
<li><code>check_block</code>: A multiprocessing lock that is used to check for a new block.</li>
<li><code>solvers</code>: A list of solvers to update the current block for.</li>
<li><code>curr_stats</code>: The current registration statistics to update.</li>
</ul>
<ol>
<li>
<p><strong>_solve_for_difficulty_fast_cuda</strong>:</p>
<ul>
<li>This function solves the registration process quickly using CUDA (Compute Unified Device Architecture) which is a parallel computing platform and application programming interface (API) model created by NVIDIA.</li>
<li>It takes several parameters including subtensor, wallet, netuid, output_in_place, update_interval, TPB (Threads per block), dev_id (CUDA device ID), n_samples, alpha_ (alpha for EWMA), and log_verbose.</li>
<li>The function sets up multiprocessing with shared memory, creates a worker for each CUDA device, starts the solver processes, checks for new blocks, and updates the hash rate and registration statistics.</li>
<li>If a solution is found or the wallet is already registered, the function stops the solver processes, terminates the workers, and returns the solution.</li>
</ul>
</li>
<li>
<p><strong>_terminate_workers_and_wait_for_exit</strong>:</p>
<ul>
<li>This function takes a list of worker processes as input.</li>
<li>It terminates each worker process and waits for them to exit using the join() method.</li>
</ul>
</li>
<li>
<p><strong>create_pow</strong>:</p>
<ul>
<li>This function creates a proof of work for the given subtensor and wallet.</li>
<li>It takes several parameters including subtensor, wallet, netuid, output_in_place, cuda, dev_id, tpb (Threads per block), num_processes, update_interval, and log_verbose.</li>
<li>If the cuda parameter is True, the function uses the _solve_for_difficulty_fast_cuda function; otherwise, it uses the _solve_for_difficulty_fast function to find a solution.</li>
<li>The function returns the proof of work solution or None if the wallet is already registered or there is a different error.</li>
<li>It raises a ValueError if the subnet does not exist.</li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="axons-in-depth-from-the-init-file-found-within-bittensor_axon"><a class="header" href="#axons-in-depth-from-the-init-file-found-within-bittensor_axon">Axons in-depth from the <strong>init</strong> file found within bittensor/_axon</a></h1>
<p>The Axon module provides a factory class for the <code>bittensor.Axon</code> object, which creates a gRPC server for the Bittensor network, facilitating communication between neurons. The server protocol is defined in <code>bittensor.proto</code> and outlines how forward and backward requests are transported and encoded between validators and servers.</p>
<h2 id="key-components-3"><a class="header" href="#key-components-3">Key Components</a></h2>
<ul>
<li><strong>Axon Factory Class</strong>: Creates a <code>bittensor.Axon</code> object from passed arguments.</li>
<li><strong>Synapse Functions</strong>: Axon supports various synapse functions for different types of requests (e.g., <code>forward_text</code>, <code>backward_text</code>, <code>synapse_last_hidden</code>, <code>synapse_causal_lm</code>, <code>synapse_causal_lm_next</code>, and <code>synapse_seq_2_seq</code>).</li>
<li><strong>Timeouts</strong>: Axon allows specifying timeouts for synapse functions and forward/backward requests.</li>
<li><strong>Thread Pool and Server</strong>: The module supports the use of a custom thread pool or gRPC server, and provides default options for both.</li>
<li><strong>Blacklist and Priority</strong>: Axon supports custom blacklist and priority functions for handling requests.</li>
<li><strong>IP and Port Configuration</strong>: The module allows for setting internal and external IP addresses and ports.</li>
</ul>
<h2 id="example-usage-1"><a class="header" href="#example-usage-1">Example Usage</a></h2>
<h2 id="additional-components"><a class="header" href="#additional-components">Additional Components</a></h2>
<ul>
<li><strong>Wallet</strong>: The Axon module supports the use of a custom wallet with hotkey and coldkeypub.</li>
<li><strong>Compression</strong>: Axon allows for setting different gRPC compression algorithms, such as gzip, deflate, or no compression.</li>
<li><strong>Synapse Checks</strong>: The module provides a default synapse check function and allows using a custom synapse check function.</li>
<li><strong>Prometheus Level</strong>: Axon allows specifying the prometheus level for monitoring.</li>
</ul>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<p>The Axon module relies on a configuration object, which can be customized to modify various aspects of its behavior. The following options can be set:</p>
<ul>
<li>port: Binding port.</li>
<li>ip: Binding IP.</li>
<li>external_ip: The external IP of the server to broadcast to the network.</li>
<li>external_port: The external port of the server to broadcast to the network.</li>
<li>protocol: The protocol of the server to broadcast to the network.</li>
<li>max_workers: Specifies the number of active threads servicing requests.</li>
<li>maximum_concurrent_rpcs: Maximum allowed concurrently processed RPCs.</li>
<li>forward_timeout: Timeout on the forward requests.</li>
<li>backward_timeout: Timeout on the backward requests.</li>
<li>compression: The gRPC compression algorithm to use.</li>
</ul>
<h2 id="customizing-axon"><a class="header" href="#customizing-axon">Customizing Axon</a></h2>
<p>The Axon module is designed to be flexible and customizable. Users can provide their own implementations for various components, such as synapse functions, blacklist functions, priority functions, and check functions. By providing custom implementations, users can tailor Axon's behavior to better suit their needs.</p>
<h2 id="advanced-usage"><a class="header" href="#advanced-usage">Advanced Usage</a></h2>
<p>For more advanced use cases, users can create a custom gRPC server or thread pool and pass it to the Axon module. This allows for greater control over the server's behavior and resource allocation. Additionally, users can set custom timeouts for synapse functions, forward requests, and backward requests to control the response times of their Axon instances.</p>
<p>Overall, the Axon module provides a powerful and flexible framework for creating gRPC servers on the Bittensor network, allowing for seamless communication between neurons and enabling a wide range of applications.</p>
<div style="break-before: page; page-break-before: always;"></div><p><code>bittensor/bittensor/_dendrite/dendrite_impl.py</code></p>
<h1 id="the-following-is-a-synposis-and-in-depth-analysis-of-what-this-file-does"><a class="header" href="#the-following-is-a-synposis-and-in-depth-analysis-of-what-this-file-does">The following is a synposis and in-depth analysis of what this file does.</a></h1>
<h6 id="this-is-a-lot-of-analysis-to-piece-together-please-look-through-it-before-posting-it-to-official-documents"><a class="header" href="#this-is-a-lot-of-analysis-to-piece-together-please-look-through-it-before-posting-it-to-official-documents"><strong>this is a lot of analysis to piece together please look through it before posting it to official documents</strong></a></h6>
<h3 id="import-statements"><a class="header" href="#import-statements">Import Statements</a></h3>
<ul>
<li>Import necessary modules and packages including <code>torch</code>, <code>pandas</code>, <code>random</code>, <code>time</code>, <code>uuid</code>, and others.</li>
<li>Import bittensor-related classes such as <code>Endpoint</code>, <code>serializer</code>, and <code>synapse</code>.</li>
</ul>
<h3 id="logger-configuration"><a class="header" href="#logger-configuration">Logger Configuration</a></h3>
<ul>
<li>Set up the logger for logging purposes.</li>
</ul>
<h3 id="global-prometheus"><a class="header" href="#global-prometheus">Global Prometheus</a></h3>
<ul>
<li>Set up Prometheus client with <code>Summary</code>, <code>Counter</code>, <code>Histogram</code>, and <code>CollectorRegistry</code>.</li>
</ul>
<h3 id="dendrite-class"><a class="header" href="#dendrite-class">Dendrite Class</a></h3>
<ul>
<li>The <code>Dendrite</code> class is an implementation of <code>bittensor.dendrite()</code> and operates as a torch autograd-friendly operation.</li>
<li>It accepts a list of <code>bittensor.endpoints</code> and a list of <code>torch</code> tensors.</li>
<li>Implements <code>__init__()</code>, <code>__str__()</code>, <code>__repr__()</code>, and <code>__del__()</code> methods.</li>
<li>The <code>forward()</code> method is a static method that handles the autograd-friendly forward RPC call to a list of neuron endpoints.</li>
</ul>
<h3 id="dendrite-class-continued"><a class="header" href="#dendrite-class-continued">Dendrite Class (continued)</a></h3>
<h4 id="backward-method"><a class="header" href="#backward-method">Backward Method</a></h4>
<ul>
<li>Implements the <code>backward()</code> method as a static and once_differentiable method.</li>
<li>This internal autograd-friendly Backward RPC call sends gradients to a list of neuron endpoints.</li>
<li>Takes the following arguments: <code>ctx</code>, <code>unused_code_grads</code>, <code>unused_time_grads</code>, and <code>*output_grads</code>.</li>
<li>Returns a tuple with optional tensors.</li>
</ul>
<h4 id="_forward-method"><a class="header" href="#_forward-method">_forward Method</a></h4>
<ul>
<li>Implements the <code>_forward()</code> method to forward tensor inputs to a list of neuron endpoints.</li>
<li>Takes the following arguments: <code>endpoints</code>, <code>synapses</code>, <code>inputs</code>, <code>timeout</code>, and <code>requires_grad</code>.</li>
<li>Returns a tuple containing <code>outputs</code>, <code>codes</code>, and <code>times</code>.</li>
</ul>
<h4 id="prometheus-counters"><a class="header" href="#prometheus-counters">Prometheus Counters</a></h4>
<ul>
<li>Sets up various Prometheus counters to track performance metrics.</li>
<li>Tracks metrics for success and failure rates, response bytes, response params, and latency.</li>
<li>Offers additional debugging information with the DEBUG level enabled.</li>
</ul>
<h3 id="generate"><a class="header" href="#generate">generate</a></h3>
<p>Generates text using provided <code>endpoints</code>, <code>prompt</code>, and various other parameters that control the text generation process.</p>
<ul>
<li><strong>endpoints</strong>: The endpoints to send inputs to.</li>
<li><strong>prompt</strong>: Tokenized sentences to send on the wire.</li>
<li><strong>timeout</strong>: Request timeout (optional).</li>
<li>Various other parameters related to text generation.</li>
</ul>
<p>Returns a tuple containing the prompt generations produced by endpoints with corresponding parsed codes and query times.</p>
<h3 id="text"><a class="header" href="#text">text</a></h3>
<p>Forwards text inputs to a list of neuron endpoints and returns logit encodings or timeouts.</p>
<ul>
<li><strong>endpoints</strong>: The endpoints to send inputs to.</li>
<li><strong>synapses</strong>: Bittensor synapse objects with arguments.</li>
<li><strong>inputs</strong>: Tokenized sentences to send on the wire.</li>
<li><strong>timeout</strong>: Request timeout (optional).</li>
<li><strong>requires_grad</strong>: If true, the backward pass triggers passing gradients on the wire (optional).</li>
</ul>
<p>Returns a tuple containing outputs from synapses, return codes per call per synapse, and times per call per synapse.</p>
<h3 id="text_causal_lm"><a class="header" href="#text_causal_lm">text_causal_lm</a></h3>
<p>Forward text inputs to a list of neuron endpoints and returns logit encodings or timeout.</p>
<ul>
<li><strong>endpoints</strong>: Endpoints to send inputs to. Endpoint can be one of the following types:
<ul>
<li>a single endpoint tensor shape [250]</li>
<li>a set of endpoint tensors shape [n, 250]</li>
<li>a list of endpoints tensors each of shape [250]</li>
<li>a single endpoint object. Inputs will be sent to this endpoint alone.</li>
<li>a list of endpoint objects. All inputs will be sent to these endpoints.</li>
</ul>
</li>
<li><strong>inputs</strong>: Tokenized sentences to send on the wire. Inputs can be one of the following types:
<ul>
<li>a single string: the string will be tokenized using the bittensor tokenizer.</li>
<li>a list of strings: the strings will be tokenized using the bittensor tokenizer.</li>
<li>a tensor with shape [batch_size, sequence_len], assumed to be the output of bittensor tokenizer.</li>
<li>a tensor with shape [n, batch_size, sequence_len], the operation will unbind the tensor and pass inputs to endpoints.</li>
<li>a list of tensors of type long each representing a tokenized sentence to be sent to each endpoint.</li>
</ul>
</li>
<li><strong>synapse</strong>: Synapse axon function call which defaults to bittensor.synapse.TextCausalLM().</li>
<li><strong>timeout</strong>: Request timeout. Queries that do not respond will be replaced by zeros.</li>
<li><strong>requires_grad</strong>: If true, the backward pass triggers passing gradients on the wire.</li>
</ul>
<p>Returns:</p>
<ul>
<li><strong>outputs</strong>: List of output logit encodings of inputs produced by each remote endpoints. Non-responses are zeroes of input shape plus output dimension. The first dimension will match the number of endpoints queried.</li>
<li><strong>codes</strong>: dendrite call return ops.</li>
<li><strong>times</strong>: times per call.</li>
</ul>
<h3 id="text_causal_lm_next"><a class="header" href="#text_causal_lm_next">text_causal_lm_next</a></h3>
<p>Forward text inputs to a list of neuron endpoints and returns logit encodings or timeout.</p>
<ul>
<li><strong>endpoints</strong>: Endpoints to send inputs to. Endpoint can be one of the following types:
<ul>
<li>a single endpoint tensor shape [250]</li>
<li>a set of endpoint tensors shape [n, 250]</li>
<li>a list of endpoints tensors each of shape [250]</li>
<li>a single endpoint object. Inputs will be sent to this endpoint alone.</li>
<li>a list of endpoint objects. All inputs will be sent to these endpoints.</li>
</ul>
</li>
<li><strong>inputs</strong>: Tokenized sentences to send on the wire. Inputs can be one of the following types:
<ul>
<li>a single string: the string will be tokenized using the bittensor tokenizer.</li>
<li>a list of strings: the strings will be tokenized using the bittensor tokenizer.</li>
<li>a tensor with shape [batch_size, sequence_len], assumed to be the output of bittensor tokenizer.</li>
<li>a tensor with shape [n, batch_size, sequence_len], the operation will unbind the tensor and pass inputs to endpoints.</li>
<li>a list of tensors of type long each representing a tokenized sentence to be sent to each endpoint.</li>
</ul>
</li>
<li><strong>synapse</strong>: Synapse axon function call which defaults to bittensor.synapse.TextCausalLMNext().</li>
<li><strong>timeout</strong>: Request timeout. Queries that do not respond will be replaced by zeros.</li>
<li><strong>requires_grad</strong>: If true, the backward pass triggers passing gradients on the wire.</li>
</ul>
<p>Returns:</p>
<ul>
<li><strong>outputs</strong>: List of output topk phrases encodings of inputs produced by each remote endpoints. Non-responses are zeroes of input shape plus output dimension. The first dimension will match the number of endpoints queried.</li>
<li><strong>codes</strong>: dendrite call return ops.</li>
<li><strong>times</strong>: times per call.</li>
</ul>
<h1 id="text_last_hidden_state"><a class="header" href="#text_last_hidden_state">text_last_hidden_state</a></h1>
<p>The <code>text_last_hidden_state</code> function is designed to forward text inputs to a list of neuron endpoints and return the last hidden state responses or time out.</p>
<h2 id="arguments"><a class="header" href="#arguments">Arguments</a></h2>
<ul>
<li><strong>endpoints</strong>: The endpoints to send the inputs to. This can be a single endpoint tensor, a set of endpoint tensors, a list of endpoint tensors, a single endpoint object, or a list of endpoint objects.</li>
<li><strong>inputs</strong>: The tokenized sentences to send on the wire. This can be a single string, a list of strings, a tensor with a specific shape, or a list of tensors of type long.</li>
<li><strong>mask</strong>: An optional mask used to select which hidden states of the sequence are to be returned by the query. This can be a single int, a list of ints, or None.</li>
<li><strong>synapse</strong>: An optional synapse axon function call that defaults to <code>bittensor.synapse.TextLastHiddenState</code>.</li>
</ul>
<h2 id="returns"><a class="header" href="#returns">Returns</a></h2>
<ul>
<li><strong>outputs</strong>: List of output last hidden state encodings of inputs produced by remote endpoints. Non-responses are zeroes of input shape plus output dimension. The first dimension will match the number of endpoints queried.</li>
<li><strong>codes</strong>: Dendrite call return ops as a LongTensor.</li>
<li><strong>times</strong>: Times per call as a FloatTensor.</li>
</ul>
<h1 id="format_text_inputs"><a class="header" href="#format_text_inputs">format_text_inputs</a></h1>
<p>The <code>format_text_inputs</code> function formats endpoint and inputs args to a common format.</p>
<h2 id="arguments-1"><a class="header" href="#arguments-1">Arguments</a></h2>
<ul>
<li>
<p><strong>endpoints</strong>: Endpoints to send inputs to. Endpoint can be one of the following types:</p>
<ul>
<li>a single endpoint tensor shape [250]</li>
<li>a set of endpoint tensors shape [n, 250]</li>
<li>a list of endpoints tensors each of shape [250]</li>
<li>a single endpoint object. Inputs will be sent to this endpoint alone.</li>
<li>a list of endpoint objects. All inputs will be sent to these endpoints.</li>
</ul>
</li>
<li>
<p><strong>inputs</strong>: Tokenized sentences to send on the wire. Inputs can be one of the following types:</p>
<ul>
<li>a single string: the string will be tokenized using the bittensor tokenizer.</li>
<li>a list of strings: the strings will be tokenized using the bittensor tokenizer.</li>
<li>a tensor with shape [batch_size, sequence_len], assumed to be the output of bittensor tokenizer.</li>
<li>a tensor with shape [n, batch_size, sequence_len], the operation will unbind the tensor and pass inputs to endpoints.
If inputs are tensors they will be cast to int64 format before sending on the wire.</li>
</ul>
</li>
</ul>
<h2 id="returns-1"><a class="header" href="#returns-1">Returns</a></h2>
<ul>
<li><strong>formatted_endpoints</strong>: A list of endpoint objects. All inputs will be sent to these endpoints.</li>
<li><strong>formatted_inputs</strong>: A list of tensor of type long each representing a tokenized sentence to be sent to each endpoint.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prometheus"><a class="header" href="#prometheus">Prometheus</a></h1>
<p><code>bittensor/bittensor/_prometheus/__init__.py</code></p>
<h2 id="overview-of-the-prometheus-module-in-bittensor"><a class="header" href="#overview-of-the-prometheus-module-in-bittensor">Overview of the Prometheus Module in Bittensor</a></h2>
<p>The <code>prometheus</code> module in Bittensor is responsible for managing and serving metrics related to the distributed machine learning system. This module utilizes the Prometheus monitoring system and the Loguru logging library to provide a powerful and flexible logging mechanism for Bittensor. The key aspects of the <code>prometheus</code> module are summarized below:</p>
<ol>
<li>
<p><strong>Prometheus Namespace</strong>: The <code>prometheus</code> class serves as a namespace for Prometheus tooling and global state variables, such as the port and logging level.</p>
</li>
<li>
<p><strong>Logging Levels</strong>: The <code>prometheus.level</code> enumeration defines the available logging levels: OFF, INFO, and DEBUG.</p>
</li>
<li>
<p><strong>Configuration</strong>: The module provides methods for managing the configuration of the Prometheus system, such as <code>config()</code>, <code>add_args()</code>, <code>add_defaults()</code>, and <code>check_config()</code>.</p>
</li>
<li>
<p><strong>Serving Metrics</strong>: The <code>serve()</code> method is responsible for starting the Prometheus server and exposing metrics on a specified port.</p>
</li>
<li>
<p><strong>Help and Argument Parsing</strong>: The <code>help()</code> method prints help information about the module to the console, and the <code>add_args()</code> method is responsible for adding module-specific arguments to an ArgumentParser.</p>
</li>
</ol>
<p>In summary, the <code>prometheus</code> module in Bittensor provides a robust and user-friendly way to manage and serve system metrics. By leveraging the power of the Prometheus monitoring system and the Loguru logging library, this module allows developers to monitor and debug the distributed machine learning system effectively.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="receptor-class-from"><a class="header" href="#receptor-class-from">Receptor Class from</a></h1>
<p><code>bittensor/bittensor/_receptor/receptor_impl.py</code></p>
<p>The Receptor class is responsible for managing a gRPC connection with a remote Bittensor neuron.</p>
<h2 id="properties-3"><a class="header" href="#properties-3">Properties</a></h2>
<ul>
<li>wallet: bittensor wallet with hotkey and coldkeypub.</li>
<li>endpoint: neuron endpoint descriptor proto.</li>
<li>channel: gRPC TCP channel.</li>
<li>stub: bittensor protocol stub created from channel.</li>
<li>receptor_uid: unique identifier for the receptor.</li>
<li>semaphore: a threading.Semaphore object to limit concurrent processes.</li>
<li>state_dict: dictionary of connectivity states.</li>
<li>stats: a SimpleNamespace object containing various statistics for the Receptor.</li>
</ul>
<h2 id="methods-8"><a class="header" href="#methods-8">Methods</a></h2>
<ul>
<li><strong><strong>init</strong></strong>: Initializes a receptor gRPC connection.</li>
<li><strong><strong>str</strong></strong>: Returns a string representation of the Receptor object.</li>
<li><strong><strong>repr</strong></strong>: Returns the string representation of the Receptor object (same as <code>__str__</code>).</li>
<li><strong><strong>del</strong></strong>: Destructor for the Receptor object.</li>
<li><strong><strong>exit</strong></strong>: Exit method for the Receptor object.</li>
<li><strong>sign</strong>: Generates a signature string for the receptor.</li>
<li><strong>nonce</strong>: Creates a string representation of the time (monotonic_ns).</li>
<li><strong>state</strong>: Returns the current connectivity state of the receptor.</li>
<li><strong>close</strong>: Closes the Receptor connection.</li>
<li><strong>forward</strong>: Triggers the gRPC call to the remote endpoint.</li>
<li><strong>backward</strong>: Triggers the gRPC backward call to the remote endpoint.</li>
<li><strong>async_forward</strong>: Asynchronous version of the <code>forward</code> method.</li>
</ul>
<h3 id="backward"><a class="header" href="#backward">backward</a></h3>
<p>Triggers the gRPC backward call to the remote endpoint, which triggers the synapse's backward calls with arguments. This method returns a list of output gradient tensors, one per synapse, along with their corresponding time and bittensor.proto.ReturnCode.</p>
<h4 id="arguments-2"><a class="header" href="#arguments-2">Arguments</a></h4>
<ul>
<li>synapses: List of Bittensor synapse objects with arguments.</li>
<li>inputs: Single torch tensor input corresponding to the linked forward call.</li>
<li>grads: List of torch tensor gradients associated with each synapse.</li>
<li>timeout: Request max timeout</li>
</ul>
<h4 id="returns-2"><a class="header" href="#returns-2">Returns</a></h4>
<ul>
<li>output: Result tensors (likely zero) from the backward call, each corresponding to a single forward input.</li>
<li>codes: List of return codes associated with each passed synapse enum.</li>
<li>times: List of times for each call associated with each passed synapse enum.</li>
</ul>
<h3 id="async_forward"><a class="header" href="#async_forward">async_forward</a></h3>
<p>Asynchronous version of the <code>forward</code> method. Triggers the gRPC call to the remote endpoint and returns a list of output tensors, one per synapse, along with their corresponding time and bittensor.proto.ReturnCode.</p>
<h4 id="arguments-3"><a class="header" href="#arguments-3">Arguments</a></h4>
<ul>
<li>synapses: List of Bittensor synapse objects with arguments.</li>
<li>inputs: Single torch tensor to be sent to the remote endpoint.</li>
<li>timeout: Request max timeout</li>
</ul>
<h4 id="returns-3"><a class="header" href="#returns-3">Returns</a></h4>
<ul>
<li>outputs: List of result tensors from the forward call, each corresponding to a passed synapse enum.</li>
<li>codes: List of return codes associated with each passed synapse enum.</li>
<li>times: List of times for each call associated with each passed synapse enum.</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
